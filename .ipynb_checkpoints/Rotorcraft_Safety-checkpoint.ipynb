{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "Training accuracy with kNN: 0.9435816343818829\n",
    "Validation accuracy with kNN: 0.9334763948497854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "/home/khanhi83/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
    "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
    "Training accuracy with Random Forest: 0.9952561134014797\n",
    "Validation accuracy with Random Forest: 0.9281115879828327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "Training accuracy with Neural Networks: 0.8472\n",
    "Validation accuracy with Neural Networks: 0.8294\n",
    "Training loss with Neural Networks: 0.0030\n",
    "Validation loss with Neural Networks: 4.2113\n",
    "Number of Training Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/khanhi83/anaconda3/envs/PY3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . /home/khanhi83/.local/share/virtualenvs/Rotorcraft-Safety-BOPmdVWD/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To activate this project's virtualenv, run pipenv shell.\n",
    "# Alternatively, run a command inside the virtualenv with pipenv run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import structlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !which python\n",
    "# !conda install -c conda-forge structlog\n",
    "# !pip install typing_extensions\n",
    "# import structlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/khanhi83/anaconda3/envs/PY3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# For mutliple devices (GPUs: 4, 5, 6, 7)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "# import structlog\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow import keras, one_hot\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (16.0, 12.0)})\n",
    "# _LOGGER = structlog.get_logger(__file__)\n",
    "HEADER_COLUMN = 12\n",
    "LABEL_COLUMN = 'False Warning'\n",
    "TEXT_COLUMN = 'Text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_file(url: str, local_dir: str = '.', local_filename: str = '') -> str:\n",
    "    \"\"\"\n",
    "    Downloads a file from a provided url to a local directory\n",
    "    :param url: URL to download the file from\n",
    "    :param local_dir: Local directory to download the file to (created if it does not exist)\n",
    "    :param local_filename: What to name the file when saved\n",
    "     (if empty or none, assume the name of the original name of the file)\n",
    "    :return: the name of the file which was saved\n",
    "    \"\"\"\n",
    "    os.makedirs(f'{local_dir}', exist_ok=True)\n",
    "    local_filename = local_filename if local_filename else url.split('/')[-1]\n",
    "    if os.path.exists(f'{local_dir}/{local_filename}'):\n",
    "#         _LOGGER.info(f'{local_dir}/{local_filename} already exists. Skipping download.')\n",
    "        print(\"{0}/{1} already exists. Skipping download.\".format(local_dir, local_filename))\n",
    "    else:\n",
    "#         _LOGGER.info(f\"Downloading file from {url} to {local_dir}/{local_filename}.\")\n",
    "        print(\"Downloading file from {0} to {1}/{2}.\".format(url, local_dir, local_filename))\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(f'./{local_dir}/{local_filename}', 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "#         _LOGGER.info(f\"Finished saving file from {url} to {local_dir}/{local_filename}.\")\n",
    "        print(\"Finished saving file from {0} to {1}/{2}.\".format(url, local_dir, local_filename))\n",
    "    return f'{local_dir}/{local_filename}'\n",
    "\n",
    "\n",
    "def unzip_file(path_to_zip_file: str, dir_to_extract_to: str) -> str:\n",
    "    \"\"\"\n",
    "    Unzips a zip file to a provided directory\n",
    "    :param path_to_file: path to zip file\n",
    "    :param dir_to_extract_to: directory to extract zip file\n",
    "    :return: full path to unzipped file (assuming there is only one)\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dir_to_extract_to)\n",
    "        return f'{dir_to_extract_to}/{zip_ref.namelist()[0]}'\n",
    "\n",
    "\n",
    "def load_data(path_to_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads excel data from a supplied path into a Pandas dataframe\n",
    "    :param path_to_file: path to excel file\n",
    "    :return: Pandas dataframe containing contents of excel spreadsheet\n",
    "    \"\"\"\n",
    "#     _LOGGER.info(f\"Started loading the excel data from {path_to_file} into a dataframe - this may take a while. \"\n",
    "#                  f\"You may want to grab a coffee.\")\n",
    "    print(\"Started loading the excel data from {0} into a datafram - this may take a while. You may want to grab a coffee.\".format(path_to_file))\n",
    "    df = pd.read_excel(path_to_file, engine='openpyxl', header=HEADER_COLUMN)\n",
    "#     _LOGGER.info(f\"Finished loading the excel data from {path_to_file} into a dataframe.\")\n",
    "    print(\"Finished loading the excel data from {0} into a dataframe.\".format(path_to_file))\n",
    "    return df\n",
    "\n",
    "\n",
    "def vectorize(df: pd.DataFrame, **kwargs) -> Tuple[np.array, List[str]]:\n",
    "#     _LOGGER.info(\"Converting text to feature matrix\")\n",
    "    print(\"Converting text to feature matrix\")\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "    sparse_matrix = vectorizer.fit_transform(df[TEXT_COLUMN])\n",
    "    feature_matrix = sparse_matrix.todense()\n",
    "    return feature_matrix, vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "def extract_and_encode_labels(df: pd.DataFrame) -> Tuple[np.array, Dict[str, int]]:\n",
    "    label_mapping = dict((label, i) for i, label in enumerate(df[LABEL_COLUMN].unique()))\n",
    "    labels = list(df[LABEL_COLUMN].map(label_mapping))\n",
    "    return np.array(labels), label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanhi83/anaconda3/envs/PY3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,5,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,87,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,117,118,119,121,122,123,124,125,126,127,128,130,131,132,145,146,148,215,224) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 3198 records because Text was null or NaN\n",
      "Dropped 4438 records because False Warning was null or NaN\n",
      "Converting text to feature matrix\n",
      "Training on 17707 sample, validating on 932 samples\n",
      "Number of features: 2285\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2285)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8192)              18726912  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 36,625,374\n",
      "Trainable params: 36,625,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17707 samples, validate on 932 samples\n",
      "Epoch 1/500\n",
      "17707/17707 [==============================] - 2s 117us/sample - loss: 0.4326 - accuracy: 0.0000e+00 - val_loss: 0.3355 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.3154 - accuracy: 0.0017 - val_loss: 0.3075 - val_accuracy: 0.0050\n",
      "Epoch 3/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.2230 - accuracy: 0.0166 - val_loss: 0.2491 - val_accuracy: 0.0182\n",
      "Epoch 4/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.1450 - accuracy: 0.0513 - val_loss: 0.2704 - val_accuracy: 0.0674\n",
      "Epoch 5/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 0.1069 - accuracy: 0.0933 - val_loss: 0.3219 - val_accuracy: 0.1023\n",
      "Epoch 6/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0668 - accuracy: 0.1396 - val_loss: 0.3775 - val_accuracy: 0.1431\n",
      "Epoch 7/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0517 - accuracy: 0.1613 - val_loss: 0.4163 - val_accuracy: 0.1570\n",
      "Epoch 8/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0427 - accuracy: 0.1670 - val_loss: 0.4299 - val_accuracy: 0.1626\n",
      "Epoch 9/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0355 - accuracy: 0.1795 - val_loss: 0.4548 - val_accuracy: 0.1826\n",
      "Epoch 10/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0282 - accuracy: 0.2041 - val_loss: 0.5231 - val_accuracy: 0.2008\n",
      "Epoch 11/500\n",
      "17707/17707 [==============================] - 1s 71us/sample - loss: 0.0204 - accuracy: 0.2377 - val_loss: 0.6140 - val_accuracy: 0.2707\n",
      "Epoch 12/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0162 - accuracy: 0.3038 - val_loss: 0.7183 - val_accuracy: 0.3169\n",
      "Epoch 13/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 0.0126 - accuracy: 0.3571 - val_loss: 0.7730 - val_accuracy: 0.3716\n",
      "Epoch 14/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 0.0097 - accuracy: 0.4048 - val_loss: 0.7942 - val_accuracy: 0.4129\n",
      "Epoch 15/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0080 - accuracy: 0.4286 - val_loss: 0.8750 - val_accuracy: 0.4269\n",
      "Epoch 16/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0066 - accuracy: 0.4582 - val_loss: 0.9070 - val_accuracy: 0.4875\n",
      "Epoch 17/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0045 - accuracy: 0.4885 - val_loss: 0.9769 - val_accuracy: 0.4773\n",
      "Epoch 18/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0027 - accuracy: 0.5153 - val_loss: 1.0606 - val_accuracy: 0.5198\n",
      "Epoch 19/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0018 - accuracy: 0.5553 - val_loss: 1.0766 - val_accuracy: 0.5438\n",
      "Epoch 20/500\n",
      "17707/17707 [==============================] - 1s 72us/sample - loss: 0.0020 - accuracy: 0.5712 - val_loss: 1.1372 - val_accuracy: 0.5749\n",
      "Epoch 21/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 0.0018 - accuracy: 0.5852 - val_loss: 1.1419 - val_accuracy: 0.5928\n",
      "Epoch 22/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0014 - accuracy: 0.6014 - val_loss: 1.1583 - val_accuracy: 0.6130\n",
      "Epoch 23/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 7.3141e-04 - accuracy: 0.6088 - val_loss: 1.1869 - val_accuracy: 0.6039\n",
      "Epoch 24/500\n",
      "17707/17707 [==============================] - 1s 71us/sample - loss: 5.5899e-04 - accuracy: 0.6163 - val_loss: 1.2050 - val_accuracy: 0.6143\n",
      "Epoch 25/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 4.6738e-04 - accuracy: 0.6195 - val_loss: 1.2219 - val_accuracy: 0.6186\n",
      "Epoch 26/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.1275e-04 - accuracy: 0.6269 - val_loss: 1.2336 - val_accuracy: 0.6252\n",
      "Epoch 27/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.6978e-04 - accuracy: 0.6313 - val_loss: 1.2394 - val_accuracy: 0.6298\n",
      "Epoch 28/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.3121e-04 - accuracy: 0.6346 - val_loss: 1.2528 - val_accuracy: 0.6320\n",
      "Epoch 29/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 2.9576e-04 - accuracy: 0.6379 - val_loss: 1.2649 - val_accuracy: 0.6352\n",
      "Epoch 30/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.6565e-04 - accuracy: 0.6407 - val_loss: 1.2783 - val_accuracy: 0.6389\n",
      "Epoch 31/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 2.3566e-04 - accuracy: 0.6445 - val_loss: 1.2950 - val_accuracy: 0.6452\n",
      "Epoch 32/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.1002e-04 - accuracy: 0.6481 - val_loss: 1.3208 - val_accuracy: 0.6504\n",
      "Epoch 33/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.8694e-04 - accuracy: 0.6529 - val_loss: 1.3226 - val_accuracy: 0.6495\n",
      "Epoch 34/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.6595e-04 - accuracy: 0.6544 - val_loss: 1.3441 - val_accuracy: 0.6552\n",
      "Epoch 35/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.4784e-04 - accuracy: 0.6572 - val_loss: 1.3598 - val_accuracy: 0.6579\n",
      "Epoch 36/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 1.3216e-04 - accuracy: 0.6623 - val_loss: 1.3807 - val_accuracy: 0.6631\n",
      "Epoch 37/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.2609e-04 - accuracy: 0.6653 - val_loss: 1.3978 - val_accuracy: 0.6640\n",
      "Epoch 38/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.1182e-04 - accuracy: 0.6687 - val_loss: 1.4204 - val_accuracy: 0.6692\n",
      "Epoch 39/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.1153e-04 - accuracy: 0.6719 - val_loss: 1.4327 - val_accuracy: 0.6701\n",
      "Epoch 40/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0119e-04 - accuracy: 0.6748 - val_loss: 1.4472 - val_accuracy: 0.6724\n",
      "Epoch 41/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.6301e-05 - accuracy: 0.6773 - val_loss: 1.4693 - val_accuracy: 0.6788\n",
      "Epoch 42/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.1075e-05 - accuracy: 0.6818 - val_loss: 1.4876 - val_accuracy: 0.6792\n",
      "Epoch 43/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.6789e-05 - accuracy: 0.6857 - val_loss: 1.5125 - val_accuracy: 0.6878\n",
      "Epoch 44/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.2074e-05 - accuracy: 0.6924 - val_loss: 1.5339 - val_accuracy: 0.6887\n",
      "Epoch 45/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.0981e-05 - accuracy: 0.6942 - val_loss: 1.5475 - val_accuracy: 0.6903\n",
      "Epoch 46/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 7.7120e-05 - accuracy: 0.6962 - val_loss: 1.5699 - val_accuracy: 0.6956\n",
      "Epoch 47/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.1647e-05 - accuracy: 0.7003 - val_loss: 1.6019 - val_accuracy: 0.7008\n",
      "Epoch 48/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 6.6153e-05 - accuracy: 0.7061 - val_loss: 1.6271 - val_accuracy: 0.7067\n",
      "Epoch 49/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 6.1064e-05 - accuracy: 0.7163 - val_loss: 1.6526 - val_accuracy: 0.7083\n",
      "Epoch 50/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.6712e-05 - accuracy: 0.7148 - val_loss: 1.6514 - val_accuracy: 0.7069\n",
      "Epoch 51/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 5.7838e-05 - accuracy: 0.7141 - val_loss: 1.6740 - val_accuracy: 0.7049\n",
      "Epoch 52/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.5881e-05 - accuracy: 0.7153 - val_loss: 1.7090 - val_accuracy: 0.7130\n",
      "Epoch 53/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0011 - accuracy: 0.7072 - val_loss: 1.4957 - val_accuracy: 0.6559\n",
      "Epoch 54/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 0.0045 - accuracy: 0.6888 - val_loss: 1.4981 - val_accuracy: 0.6624\n",
      "Epoch 55/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 5.1951e-04 - accuracy: 0.6824 - val_loss: 1.5511 - val_accuracy: 0.6956\n",
      "Epoch 56/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 5.5733e-04 - accuracy: 0.6973 - val_loss: 1.6497 - val_accuracy: 0.6942\n",
      "Epoch 57/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.8909e-05 - accuracy: 0.6990 - val_loss: 1.6423 - val_accuracy: 0.6972\n",
      "Epoch 58/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.5881e-05 - accuracy: 0.7018 - val_loss: 1.6401 - val_accuracy: 0.6978\n",
      "Epoch 59/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 4.2602e-05 - accuracy: 0.7023 - val_loss: 1.6394 - val_accuracy: 0.6996\n",
      "Epoch 60/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 3.8943e-05 - accuracy: 0.7034 - val_loss: 1.6449 - val_accuracy: 0.7008\n",
      "Epoch 61/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 3.5737e-05 - accuracy: 0.7050 - val_loss: 1.6520 - val_accuracy: 0.7021\n",
      "Epoch 62/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.3066e-05 - accuracy: 0.7070 - val_loss: 1.6594 - val_accuracy: 0.7030\n",
      "Epoch 63/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.0484e-05 - accuracy: 0.7087 - val_loss: 1.6674 - val_accuracy: 0.7055\n",
      "Epoch 64/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 2.9550e-05 - accuracy: 0.7113 - val_loss: 1.6565 - val_accuracy: 0.7078\n",
      "Epoch 65/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 2.7791e-05 - accuracy: 0.7136 - val_loss: 1.6674 - val_accuracy: 0.7098\n",
      "Epoch 66/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 2.5288e-05 - accuracy: 0.7153 - val_loss: 1.6784 - val_accuracy: 0.7110\n",
      "Epoch 67/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 2.2672e-05 - accuracy: 0.7173 - val_loss: 1.6899 - val_accuracy: 0.7132\n",
      "Epoch 68/500\n",
      "17707/17707 [==============================] - 1s 72us/sample - loss: 2.0128e-05 - accuracy: 0.7195 - val_loss: 1.7007 - val_accuracy: 0.7142\n",
      "Epoch 69/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.7661e-05 - accuracy: 0.7220 - val_loss: 1.7068 - val_accuracy: 0.7171\n",
      "Epoch 70/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5426e-05 - accuracy: 0.7241 - val_loss: 1.7145 - val_accuracy: 0.7185\n",
      "Epoch 71/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4340e-05 - accuracy: 0.7267 - val_loss: 1.6938 - val_accuracy: 0.7223\n",
      "Epoch 72/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5444e-05 - accuracy: 0.7290 - val_loss: 1.7249 - val_accuracy: 0.7244\n",
      "Epoch 73/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0746e-05 - accuracy: 0.7318 - val_loss: 1.7367 - val_accuracy: 0.7255\n",
      "Epoch 74/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.0751e-06 - accuracy: 0.7333 - val_loss: 1.7464 - val_accuracy: 0.7260\n",
      "Epoch 75/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 7.5759e-06 - accuracy: 0.7350 - val_loss: 1.7563 - val_accuracy: 0.7269\n",
      "Epoch 76/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.2501e-06 - accuracy: 0.7365 - val_loss: 1.7685 - val_accuracy: 0.7280\n",
      "Epoch 77/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.6191e-06 - accuracy: 0.7386 - val_loss: 1.7555 - val_accuracy: 0.7293\n",
      "Epoch 78/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.1823e-06 - accuracy: 0.7395 - val_loss: 1.7847 - val_accuracy: 0.7316\n",
      "Epoch 79/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.6542e-06 - accuracy: 0.7421 - val_loss: 1.8016 - val_accuracy: 0.7328\n",
      "Epoch 80/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.7929e-06 - accuracy: 0.7442 - val_loss: 1.8133 - val_accuracy: 0.7344\n",
      "Epoch 81/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.3283e-06 - accuracy: 0.7463 - val_loss: 1.8089 - val_accuracy: 0.7352\n",
      "Epoch 82/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.0385e-06 - accuracy: 0.7475 - val_loss: 1.8260 - val_accuracy: 0.7359\n",
      "Epoch 83/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6087e-06 - accuracy: 0.7483 - val_loss: 1.8404 - val_accuracy: 0.7368\n",
      "Epoch 84/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 1.2734e-06 - accuracy: 0.7497 - val_loss: 1.8477 - val_accuracy: 0.7380\n",
      "Epoch 85/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 1.0055e-06 - accuracy: 0.7518 - val_loss: 1.8649 - val_accuracy: 0.7400\n",
      "Epoch 86/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.3801e-07 - accuracy: 0.7535 - val_loss: 1.8661 - val_accuracy: 0.7411\n",
      "Epoch 87/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.6404e-07 - accuracy: 0.7545 - val_loss: 1.8802 - val_accuracy: 0.7420\n",
      "Epoch 88/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.8806e-07 - accuracy: 0.7553 - val_loss: 1.8887 - val_accuracy: 0.7428\n",
      "Epoch 89/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.9296e-07 - accuracy: 0.7574 - val_loss: 1.8923 - val_accuracy: 0.7443\n",
      "Epoch 90/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.2999e-07 - accuracy: 0.7583 - val_loss: 1.9061 - val_accuracy: 0.7459\n",
      "Epoch 91/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.4814e-07 - accuracy: 0.7595 - val_loss: 1.9173 - val_accuracy: 0.7471\n",
      "Epoch 92/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.8693e-07 - accuracy: 0.7607 - val_loss: 1.9262 - val_accuracy: 0.7477\n",
      "Epoch 93/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.4933e-07 - accuracy: 0.7621 - val_loss: 1.9312 - val_accuracy: 0.7487\n",
      "Epoch 94/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 2.1591e-07 - accuracy: 0.7632 - val_loss: 1.9453 - val_accuracy: 0.7489\n",
      "Epoch 95/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.7868e-07 - accuracy: 0.7647 - val_loss: 1.9447 - val_accuracy: 0.7514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5887e-07 - accuracy: 0.7660 - val_loss: 1.9567 - val_accuracy: 0.7521\n",
      "Epoch 97/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.3061e-07 - accuracy: 0.7665 - val_loss: 1.9664 - val_accuracy: 0.7523\n",
      "Epoch 98/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.0756e-07 - accuracy: 0.7679 - val_loss: 1.9781 - val_accuracy: 0.7538\n",
      "Epoch 99/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.5416e-08 - accuracy: 0.7695 - val_loss: 1.9796 - val_accuracy: 0.7539\n",
      "Epoch 100/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 8.2171e-08 - accuracy: 0.7706 - val_loss: 1.9932 - val_accuracy: 0.7557\n",
      "Epoch 101/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 7.2589e-08 - accuracy: 0.7719 - val_loss: 1.9911 - val_accuracy: 0.7564\n",
      "Epoch 102/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 6.1532e-08 - accuracy: 0.7725 - val_loss: 2.0022 - val_accuracy: 0.7561\n",
      "Epoch 103/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.1544e-08 - accuracy: 0.7736 - val_loss: 2.0113 - val_accuracy: 0.7575\n",
      "Epoch 104/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 4.4860e-08 - accuracy: 0.7752 - val_loss: 2.0134 - val_accuracy: 0.7589\n",
      "Epoch 105/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.0357e-08 - accuracy: 0.7761 - val_loss: 2.0235 - val_accuracy: 0.7591\n",
      "Epoch 106/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.4434e-08 - accuracy: 0.7775 - val_loss: 2.0248 - val_accuracy: 0.7600\n",
      "Epoch 107/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.9903e-08 - accuracy: 0.7780 - val_loss: 2.0357 - val_accuracy: 0.7611\n",
      "Epoch 108/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.5191e-08 - accuracy: 0.7796 - val_loss: 2.0420 - val_accuracy: 0.7623\n",
      "Epoch 109/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.3273e-08 - accuracy: 0.7807 - val_loss: 2.0388 - val_accuracy: 0.7632\n",
      "Epoch 110/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.1623e-08 - accuracy: 0.7811 - val_loss: 2.0544 - val_accuracy: 0.7639\n",
      "Epoch 111/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.7342e-08 - accuracy: 0.7824 - val_loss: 2.0523 - val_accuracy: 0.7639\n",
      "Epoch 112/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5349e-08 - accuracy: 0.7827 - val_loss: 2.0648 - val_accuracy: 0.7647\n",
      "Epoch 113/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.3949e-08 - accuracy: 0.7838 - val_loss: 2.0625 - val_accuracy: 0.7656\n",
      "Epoch 114/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.2360e-08 - accuracy: 0.7847 - val_loss: 2.0717 - val_accuracy: 0.7650\n",
      "Epoch 115/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0233e-08 - accuracy: 0.7852 - val_loss: 2.0750 - val_accuracy: 0.7657\n",
      "Epoch 116/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.4049e-09 - accuracy: 0.7861 - val_loss: 2.0724 - val_accuracy: 0.7665\n",
      "Epoch 117/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 8.1932e-09 - accuracy: 0.7863 - val_loss: 2.0814 - val_accuracy: 0.7668\n",
      "Epoch 118/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 7.2776e-09 - accuracy: 0.7874 - val_loss: 2.0821 - val_accuracy: 0.7668\n",
      "Epoch 119/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 6.4495e-09 - accuracy: 0.7877 - val_loss: 2.0868 - val_accuracy: 0.7673\n",
      "Epoch 120/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.8571e-09 - accuracy: 0.7884 - val_loss: 2.0868 - val_accuracy: 0.7675\n",
      "Epoch 121/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 5.1839e-09 - accuracy: 0.7884 - val_loss: 2.0934 - val_accuracy: 0.7693\n",
      "Epoch 122/500\n",
      "17707/17707 [==============================] - 1s 71us/sample - loss: 4.7261e-09 - accuracy: 0.7894 - val_loss: 2.0925 - val_accuracy: 0.7698\n",
      "Epoch 123/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 4.1269e-09 - accuracy: 0.7898 - val_loss: 2.0997 - val_accuracy: 0.7702\n",
      "Epoch 124/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 3.7432e-09 - accuracy: 0.7905 - val_loss: 2.0957 - val_accuracy: 0.7700\n",
      "Epoch 125/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 3.2988e-09 - accuracy: 0.7907 - val_loss: 2.1028 - val_accuracy: 0.7704\n",
      "Epoch 126/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 2.8141e-09 - accuracy: 0.7911 - val_loss: 2.1024 - val_accuracy: 0.7704\n",
      "Epoch 127/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.6929e-09 - accuracy: 0.7914 - val_loss: 2.0998 - val_accuracy: 0.7706\n",
      "Epoch 128/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.3428e-09 - accuracy: 0.7915 - val_loss: 2.0996 - val_accuracy: 0.7702\n",
      "Epoch 129/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 2.1409e-09 - accuracy: 0.7920 - val_loss: 2.0994 - val_accuracy: 0.7706\n",
      "Epoch 130/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.9456e-09 - accuracy: 0.7922 - val_loss: 2.1045 - val_accuracy: 0.7704\n",
      "Epoch 131/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.7639e-09 - accuracy: 0.7926 - val_loss: 2.0983 - val_accuracy: 0.7700\n",
      "Epoch 132/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.6090e-09 - accuracy: 0.7925 - val_loss: 2.1013 - val_accuracy: 0.7704\n",
      "Epoch 133/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.4542e-09 - accuracy: 0.7926 - val_loss: 2.0946 - val_accuracy: 0.7700\n",
      "Epoch 134/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.3061e-09 - accuracy: 0.7931 - val_loss: 2.0970 - val_accuracy: 0.7704\n",
      "Epoch 135/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.2185e-09 - accuracy: 0.7933 - val_loss: 2.0896 - val_accuracy: 0.7709\n",
      "Epoch 136/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.1445e-09 - accuracy: 0.7929 - val_loss: 2.0924 - val_accuracy: 0.7711\n",
      "Epoch 137/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 9.8965e-10 - accuracy: 0.7938 - val_loss: 2.0930 - val_accuracy: 0.7709\n",
      "Epoch 138/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.1560e-10 - accuracy: 0.7936 - val_loss: 2.0882 - val_accuracy: 0.7711\n",
      "Epoch 139/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 7.9441e-10 - accuracy: 0.7937 - val_loss: 2.0835 - val_accuracy: 0.7707\n",
      "Epoch 140/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.2036e-10 - accuracy: 0.7937 - val_loss: 2.0808 - val_accuracy: 0.7711\n",
      "Epoch 141/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 6.5977e-10 - accuracy: 0.7938 - val_loss: 2.0752 - val_accuracy: 0.7709\n",
      "Epoch 142/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 6.7996e-10 - accuracy: 0.7932 - val_loss: 2.0741 - val_accuracy: 0.7713\n",
      "Epoch 143/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 5.7898e-10 - accuracy: 0.7933 - val_loss: 2.0705 - val_accuracy: 0.7711\n",
      "Epoch 144/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.1839e-10 - accuracy: 0.7938 - val_loss: 2.0656 - val_accuracy: 0.7716\n",
      "Epoch 145/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.3185e-10 - accuracy: 0.7936 - val_loss: 2.0590 - val_accuracy: 0.7713\n",
      "Epoch 146/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.7126e-10 - accuracy: 0.7932 - val_loss: 2.0593 - val_accuracy: 0.7718\n",
      "Epoch 147/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.3760e-10 - accuracy: 0.7936 - val_loss: 2.0563 - val_accuracy: 0.7715\n",
      "Epoch 148/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.4433e-10 - accuracy: 0.7935 - val_loss: 2.0478 - val_accuracy: 0.7718\n",
      "Epoch 149/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.9721e-10 - accuracy: 0.7938 - val_loss: 2.0457 - val_accuracy: 0.7709\n",
      "Epoch 150/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.5681e-10 - accuracy: 0.7934 - val_loss: 2.0448 - val_accuracy: 0.7711\n",
      "Epoch 151/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.7028e-10 - accuracy: 0.7933 - val_loss: 2.0373 - val_accuracy: 0.7716\n",
      "Epoch 152/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5008e-10 - accuracy: 0.7940 - val_loss: 2.0343 - val_accuracy: 0.7702\n",
      "Epoch 153/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.3662e-10 - accuracy: 0.7933 - val_loss: 2.0316 - val_accuracy: 0.7713\n",
      "Epoch 154/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.0295e-10 - accuracy: 0.7937 - val_loss: 2.0273 - val_accuracy: 0.7690\n",
      "Epoch 155/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.9622e-10 - accuracy: 0.7934 - val_loss: 2.0272 - val_accuracy: 0.7713\n",
      "Epoch 156/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 2.8276e-10 - accuracy: 0.7933 - val_loss: 2.0182 - val_accuracy: 0.7698\n",
      "Epoch 157/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.6256e-10 - accuracy: 0.7935 - val_loss: 2.0163 - val_accuracy: 0.7697\n",
      "Epoch 158/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.8276e-10 - accuracy: 0.7937 - val_loss: 2.0141 - val_accuracy: 0.7709\n",
      "Epoch 159/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 2.0197e-10 - accuracy: 0.7940 - val_loss: 2.0050 - val_accuracy: 0.7702\n",
      "Epoch 160/500\n",
      "17707/17707 [==============================] - 1s 71us/sample - loss: 2.4236e-10 - accuracy: 0.7946 - val_loss: 2.0058 - val_accuracy: 0.7722\n",
      "Epoch 161/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.2890e-10 - accuracy: 0.7947 - val_loss: 2.0008 - val_accuracy: 0.7704\n",
      "Epoch 162/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0870e-10 - accuracy: 0.7944 - val_loss: 1.9980 - val_accuracy: 0.7718\n",
      "Epoch 163/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.2217e-10 - accuracy: 0.7952 - val_loss: 1.9872 - val_accuracy: 0.7709\n",
      "Epoch 164/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.7504e-10 - accuracy: 0.7953 - val_loss: 1.9843 - val_accuracy: 0.7716\n",
      "Epoch 165/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4811e-10 - accuracy: 0.7946 - val_loss: 1.9832 - val_accuracy: 0.7725\n",
      "Epoch 166/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5484e-10 - accuracy: 0.7954 - val_loss: 1.9737 - val_accuracy: 0.7707\n",
      "Epoch 167/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4138e-10 - accuracy: 0.7948 - val_loss: 1.9643 - val_accuracy: 0.7716\n",
      "Epoch 168/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.4811e-10 - accuracy: 0.7949 - val_loss: 1.9547 - val_accuracy: 0.7711\n",
      "Epoch 169/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.3465e-10 - accuracy: 0.7948 - val_loss: 1.9505 - val_accuracy: 0.7715\n",
      "Epoch 170/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.2118e-10 - accuracy: 0.7949 - val_loss: 1.9473 - val_accuracy: 0.7722\n",
      "Epoch 171/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5484e-10 - accuracy: 0.7953 - val_loss: 1.9438 - val_accuracy: 0.7720\n",
      "Epoch 172/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2791e-10 - accuracy: 0.7955 - val_loss: 1.9396 - val_accuracy: 0.7727\n",
      "Epoch 173/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2791e-10 - accuracy: 0.7953 - val_loss: 1.9287 - val_accuracy: 0.7716\n",
      "Epoch 174/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0098e-10 - accuracy: 0.7956 - val_loss: 1.9260 - val_accuracy: 0.7734\n",
      "Epoch 175/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0772e-10 - accuracy: 0.7955 - val_loss: 1.9126 - val_accuracy: 0.7731\n",
      "Epoch 176/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.1445e-10 - accuracy: 0.7953 - val_loss: 1.9133 - val_accuracy: 0.7738\n",
      "Epoch 177/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0098e-10 - accuracy: 0.7955 - val_loss: 1.9149 - val_accuracy: 0.7743\n",
      "Epoch 178/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 8.7520e-11 - accuracy: 0.7944 - val_loss: 1.9048 - val_accuracy: 0.7745\n",
      "Epoch 179/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 1.2791e-10 - accuracy: 0.7947 - val_loss: 1.9052 - val_accuracy: 0.7756\n",
      "Epoch 180/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.2791e-10 - accuracy: 0.7952 - val_loss: 1.9113 - val_accuracy: 0.7770\n",
      "Epoch 181/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 9.4253e-11 - accuracy: 0.7961 - val_loss: 1.9088 - val_accuracy: 0.7763\n",
      "Epoch 182/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.0098e-10 - accuracy: 0.7957 - val_loss: 1.9043 - val_accuracy: 0.7758\n",
      "Epoch 183/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.4253e-11 - accuracy: 0.7953 - val_loss: 1.9095 - val_accuracy: 0.7752\n",
      "Epoch 184/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.4253e-11 - accuracy: 0.7953 - val_loss: 1.9098 - val_accuracy: 0.7756\n",
      "Epoch 185/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.7520e-11 - accuracy: 0.7955 - val_loss: 1.9168 - val_accuracy: 0.7754\n",
      "Epoch 186/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.0591e-11 - accuracy: 0.7958 - val_loss: 1.9127 - val_accuracy: 0.7759\n",
      "Epoch 187/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.1445e-10 - accuracy: 0.7952 - val_loss: 1.9121 - val_accuracy: 0.7765\n",
      "Epoch 188/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.0772e-10 - accuracy: 0.7969 - val_loss: 1.9195 - val_accuracy: 0.7772\n",
      "Epoch 189/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.5484e-10 - accuracy: 0.7962 - val_loss: 1.9296 - val_accuracy: 0.7768\n",
      "Epoch 190/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 7.4056e-11 - accuracy: 0.7976 - val_loss: 1.9197 - val_accuracy: 0.7756\n",
      "Epoch 191/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.2118e-10 - accuracy: 0.7970 - val_loss: 1.9240 - val_accuracy: 0.7772\n",
      "Epoch 192/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.4138e-10 - accuracy: 0.7978 - val_loss: 1.9252 - val_accuracy: 0.7765\n",
      "Epoch 193/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.2118e-10 - accuracy: 0.7974 - val_loss: 1.9296 - val_accuracy: 0.7766\n",
      "Epoch 194/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2791e-10 - accuracy: 0.7985 - val_loss: 1.9262 - val_accuracy: 0.7765\n",
      "Epoch 195/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.6831e-10 - accuracy: 0.7989 - val_loss: 1.9344 - val_accuracy: 0.7772\n",
      "Epoch 196/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6158e-10 - accuracy: 0.7999 - val_loss: 1.9350 - val_accuracy: 0.7777\n",
      "Epoch 197/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.9524e-10 - accuracy: 0.8002 - val_loss: 1.9314 - val_accuracy: 0.7749\n",
      "Epoch 198/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.2217e-10 - accuracy: 0.8021 - val_loss: 1.9541 - val_accuracy: 0.7800\n",
      "Epoch 199/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 2.4910e-10 - accuracy: 0.8029 - val_loss: 1.9513 - val_accuracy: 0.7797\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.7603e-10 - accuracy: 0.8042 - val_loss: 1.9665 - val_accuracy: 0.7852\n",
      "Epoch 201/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.9622e-10 - accuracy: 0.8054 - val_loss: 1.9794 - val_accuracy: 0.7876\n",
      "Epoch 202/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.4335e-10 - accuracy: 0.8075 - val_loss: 1.9840 - val_accuracy: 0.7863\n",
      "Epoch 203/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.1642e-10 - accuracy: 0.8090 - val_loss: 1.9936 - val_accuracy: 0.7884\n",
      "Epoch 204/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.9721e-10 - accuracy: 0.8092 - val_loss: 1.9895 - val_accuracy: 0.7867\n",
      "Epoch 205/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.7126e-10 - accuracy: 0.8105 - val_loss: 1.9964 - val_accuracy: 0.7892\n",
      "Epoch 206/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 6.7996e-10 - accuracy: 0.8128 - val_loss: 2.0087 - val_accuracy: 0.7874\n",
      "Epoch 207/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.8473e-10 - accuracy: 0.8135 - val_loss: 2.0141 - val_accuracy: 0.7927\n",
      "Epoch 208/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.4532e-10 - accuracy: 0.8141 - val_loss: 2.0317 - val_accuracy: 0.7979\n",
      "Epoch 209/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.7520e-10 - accuracy: 0.8144 - val_loss: 2.0167 - val_accuracy: 0.7929\n",
      "Epoch 210/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 4.7800e-10 - accuracy: 0.8152 - val_loss: 2.0396 - val_accuracy: 0.7985\n",
      "Epoch 211/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.6945e-10 - accuracy: 0.8161 - val_loss: 2.0423 - val_accuracy: 0.7958\n",
      "Epoch 212/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.1264e-10 - accuracy: 0.8163 - val_loss: 2.0727 - val_accuracy: 0.7997\n",
      "Epoch 213/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4205e-09 - accuracy: 0.8194 - val_loss: 2.1348 - val_accuracy: 0.8047\n",
      "Epoch 214/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.2755e-09 - accuracy: 0.8216 - val_loss: 2.1600 - val_accuracy: 0.8083\n",
      "Epoch 215/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 0.0045 - accuracy: 0.8163 - val_loss: 2.0156 - val_accuracy: 0.7983\n",
      "Epoch 216/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 0.0099 - accuracy: 0.8029 - val_loss: 2.0368 - val_accuracy: 0.7902\n",
      "Epoch 217/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 0.0012 - accuracy: 0.8066 - val_loss: 2.0211 - val_accuracy: 0.7829\n",
      "Epoch 218/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.8668e-04 - accuracy: 0.8022 - val_loss: 2.0181 - val_accuracy: 0.7799\n",
      "Epoch 219/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.0141e-07 - accuracy: 0.7976 - val_loss: 2.0155 - val_accuracy: 0.7797\n",
      "Epoch 220/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.2504e-07 - accuracy: 0.7981 - val_loss: 2.0167 - val_accuracy: 0.7802\n",
      "Epoch 221/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 3.4262e-07 - accuracy: 0.7985 - val_loss: 2.0177 - val_accuracy: 0.7804\n",
      "Epoch 222/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.8517e-07 - accuracy: 0.7989 - val_loss: 2.0187 - val_accuracy: 0.7806\n",
      "Epoch 223/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.4190e-07 - accuracy: 0.7994 - val_loss: 2.0195 - val_accuracy: 0.7806\n",
      "Epoch 224/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0908e-07 - accuracy: 0.7997 - val_loss: 2.0203 - val_accuracy: 0.7809\n",
      "Epoch 225/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.8241e-07 - accuracy: 0.8001 - val_loss: 2.0211 - val_accuracy: 0.7815\n",
      "Epoch 226/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.6008e-07 - accuracy: 0.8002 - val_loss: 2.0218 - val_accuracy: 0.7818\n",
      "Epoch 227/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.4084e-07 - accuracy: 0.8006 - val_loss: 2.0225 - val_accuracy: 0.7822\n",
      "Epoch 228/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2518e-07 - accuracy: 0.8010 - val_loss: 2.0232 - val_accuracy: 0.7824\n",
      "Epoch 229/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.1117e-07 - accuracy: 0.8013 - val_loss: 2.0239 - val_accuracy: 0.7825\n",
      "Epoch 230/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.9605e-08 - accuracy: 0.8016 - val_loss: 2.0246 - val_accuracy: 0.7827\n",
      "Epoch 231/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.9454e-08 - accuracy: 0.8019 - val_loss: 2.0252 - val_accuracy: 0.7827\n",
      "Epoch 232/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.0535e-08 - accuracy: 0.8021 - val_loss: 2.0259 - val_accuracy: 0.7827\n",
      "Epoch 233/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.2423e-08 - accuracy: 0.8026 - val_loss: 2.0266 - val_accuracy: 0.7827\n",
      "Epoch 234/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.5497e-08 - accuracy: 0.8028 - val_loss: 2.0272 - val_accuracy: 0.7833\n",
      "Epoch 235/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.8960e-08 - accuracy: 0.8032 - val_loss: 2.0278 - val_accuracy: 0.7836\n",
      "Epoch 236/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.3494e-08 - accuracy: 0.8035 - val_loss: 2.0283 - val_accuracy: 0.7836\n",
      "Epoch 237/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.8687e-08 - accuracy: 0.8037 - val_loss: 2.0288 - val_accuracy: 0.7838\n",
      "Epoch 238/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.4332e-08 - accuracy: 0.8039 - val_loss: 2.0293 - val_accuracy: 0.7842\n",
      "Epoch 239/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.0420e-08 - accuracy: 0.8041 - val_loss: 2.0300 - val_accuracy: 0.7845\n",
      "Epoch 240/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.6798e-08 - accuracy: 0.8044 - val_loss: 2.0302 - val_accuracy: 0.7847\n",
      "Epoch 241/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 3.3614e-08 - accuracy: 0.8046 - val_loss: 2.0308 - val_accuracy: 0.7851\n",
      "Epoch 242/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 3.0915e-08 - accuracy: 0.8048 - val_loss: 2.0312 - val_accuracy: 0.7852\n",
      "Epoch 243/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 2.8262e-08 - accuracy: 0.8051 - val_loss: 2.0317 - val_accuracy: 0.7852\n",
      "Epoch 244/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 2.5892e-08 - accuracy: 0.8054 - val_loss: 2.0321 - val_accuracy: 0.7854\n",
      "Epoch 245/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.3778e-08 - accuracy: 0.8056 - val_loss: 2.0326 - val_accuracy: 0.7856\n",
      "Epoch 246/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.1799e-08 - accuracy: 0.8059 - val_loss: 2.0330 - val_accuracy: 0.7861\n",
      "Epoch 247/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.0089e-08 - accuracy: 0.8061 - val_loss: 2.0335 - val_accuracy: 0.7861\n",
      "Epoch 248/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.8615e-08 - accuracy: 0.8062 - val_loss: 2.0339 - val_accuracy: 0.7861\n",
      "Epoch 249/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.7201e-08 - accuracy: 0.8065 - val_loss: 2.0345 - val_accuracy: 0.7863\n",
      "Epoch 250/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5888e-08 - accuracy: 0.8067 - val_loss: 2.0349 - val_accuracy: 0.7865\n",
      "Epoch 251/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4710e-08 - accuracy: 0.8069 - val_loss: 2.0353 - val_accuracy: 0.7868\n",
      "Epoch 252/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.3586e-08 - accuracy: 0.8071 - val_loss: 2.0358 - val_accuracy: 0.7872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.2677e-08 - accuracy: 0.8073 - val_loss: 2.0362 - val_accuracy: 0.7874\n",
      "Epoch 254/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.1694e-08 - accuracy: 0.8076 - val_loss: 2.0368 - val_accuracy: 0.7877\n",
      "Epoch 255/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0819e-08 - accuracy: 0.8079 - val_loss: 2.0373 - val_accuracy: 0.7879\n",
      "Epoch 256/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.9369e-09 - accuracy: 0.8081 - val_loss: 2.0381 - val_accuracy: 0.7881\n",
      "Epoch 257/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 9.2435e-09 - accuracy: 0.8084 - val_loss: 2.0384 - val_accuracy: 0.7881\n",
      "Epoch 258/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.5096e-09 - accuracy: 0.8086 - val_loss: 2.0391 - val_accuracy: 0.7883\n",
      "Epoch 259/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.8364e-09 - accuracy: 0.8089 - val_loss: 2.0395 - val_accuracy: 0.7886\n",
      "Epoch 260/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 7.2440e-09 - accuracy: 0.8090 - val_loss: 2.0406 - val_accuracy: 0.7892\n",
      "Epoch 261/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 6.7727e-09 - accuracy: 0.8092 - val_loss: 2.0411 - val_accuracy: 0.7892\n",
      "Epoch 262/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.1735e-09 - accuracy: 0.8095 - val_loss: 2.0418 - val_accuracy: 0.7893\n",
      "Epoch 263/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.7157e-09 - accuracy: 0.8097 - val_loss: 2.0427 - val_accuracy: 0.7897\n",
      "Epoch 264/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.2781e-09 - accuracy: 0.8100 - val_loss: 2.0433 - val_accuracy: 0.7899\n",
      "Epoch 265/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.8675e-09 - accuracy: 0.8101 - val_loss: 2.0444 - val_accuracy: 0.7901\n",
      "Epoch 266/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.4299e-09 - accuracy: 0.8103 - val_loss: 2.0451 - val_accuracy: 0.7901\n",
      "Epoch 267/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.1067e-09 - accuracy: 0.8105 - val_loss: 2.0461 - val_accuracy: 0.7902\n",
      "Epoch 268/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.8038e-09 - accuracy: 0.8108 - val_loss: 2.0473 - val_accuracy: 0.7906\n",
      "Epoch 269/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5277e-09 - accuracy: 0.8109 - val_loss: 2.0477 - val_accuracy: 0.7906\n",
      "Epoch 270/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.1440e-09 - accuracy: 0.8112 - val_loss: 2.0496 - val_accuracy: 0.7908\n",
      "Epoch 271/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.9555e-09 - accuracy: 0.8113 - val_loss: 2.0506 - val_accuracy: 0.7911\n",
      "Epoch 272/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.7131e-09 - accuracy: 0.8116 - val_loss: 2.0515 - val_accuracy: 0.7913\n",
      "Epoch 273/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 2.4034e-09 - accuracy: 0.8119 - val_loss: 2.0528 - val_accuracy: 0.7915\n",
      "Epoch 274/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.2755e-09 - accuracy: 0.8120 - val_loss: 2.0548 - val_accuracy: 0.7918\n",
      "Epoch 275/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.0399e-09 - accuracy: 0.8125 - val_loss: 2.0562 - val_accuracy: 0.7918\n",
      "Epoch 276/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.8918e-09 - accuracy: 0.8125 - val_loss: 2.0581 - val_accuracy: 0.7918\n",
      "Epoch 277/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.6898e-09 - accuracy: 0.8129 - val_loss: 2.0598 - val_accuracy: 0.7922\n",
      "Epoch 278/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.5686e-09 - accuracy: 0.8131 - val_loss: 2.0616 - val_accuracy: 0.7922\n",
      "Epoch 279/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4474e-09 - accuracy: 0.8135 - val_loss: 2.0634 - val_accuracy: 0.7924\n",
      "Epoch 280/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.2657e-09 - accuracy: 0.8138 - val_loss: 2.0653 - val_accuracy: 0.7924\n",
      "Epoch 281/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.1714e-09 - accuracy: 0.8142 - val_loss: 2.0676 - val_accuracy: 0.7931\n",
      "Epoch 282/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 1.0704e-09 - accuracy: 0.8144 - val_loss: 2.0705 - val_accuracy: 0.7931\n",
      "Epoch 283/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 9.6272e-10 - accuracy: 0.8147 - val_loss: 2.0733 - val_accuracy: 0.7936\n",
      "Epoch 284/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 8.8867e-10 - accuracy: 0.8150 - val_loss: 2.0765 - val_accuracy: 0.7938\n",
      "Epoch 285/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 7.8768e-10 - accuracy: 0.8154 - val_loss: 2.0799 - val_accuracy: 0.7942\n",
      "Epoch 286/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 7.2709e-10 - accuracy: 0.8157 - val_loss: 2.0819 - val_accuracy: 0.7943\n",
      "Epoch 287/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 6.3284e-10 - accuracy: 0.8164 - val_loss: 2.0859 - val_accuracy: 0.7947\n",
      "Epoch 288/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 5.9244e-10 - accuracy: 0.8166 - val_loss: 2.0905 - val_accuracy: 0.7951\n",
      "Epoch 289/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.3859e-10 - accuracy: 0.8172 - val_loss: 2.0945 - val_accuracy: 0.7961\n",
      "Epoch 290/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.1839e-10 - accuracy: 0.8176 - val_loss: 2.0976 - val_accuracy: 0.7961\n",
      "Epoch 291/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.9146e-10 - accuracy: 0.8181 - val_loss: 2.1036 - val_accuracy: 0.7972\n",
      "Epoch 292/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.4433e-10 - accuracy: 0.8188 - val_loss: 2.1082 - val_accuracy: 0.7974\n",
      "Epoch 293/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.8374e-10 - accuracy: 0.8194 - val_loss: 2.1132 - val_accuracy: 0.7979\n",
      "Epoch 294/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.6355e-10 - accuracy: 0.8202 - val_loss: 2.1181 - val_accuracy: 0.7983\n",
      "Epoch 295/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5681e-10 - accuracy: 0.8207 - val_loss: 2.1251 - val_accuracy: 0.7999\n",
      "Epoch 296/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.9047e-10 - accuracy: 0.8214 - val_loss: 2.1292 - val_accuracy: 0.7997\n",
      "Epoch 297/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.7028e-10 - accuracy: 0.8224 - val_loss: 2.1353 - val_accuracy: 0.8010\n",
      "Epoch 298/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.7701e-10 - accuracy: 0.8224 - val_loss: 2.1459 - val_accuracy: 0.8017\n",
      "Epoch 299/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.7701e-10 - accuracy: 0.8237 - val_loss: 2.1514 - val_accuracy: 0.8015\n",
      "Epoch 300/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.6453e-10 - accuracy: 0.8241 - val_loss: 2.1630 - val_accuracy: 0.8045\n",
      "Epoch 301/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.3087e-10 - accuracy: 0.8251 - val_loss: 2.1731 - val_accuracy: 0.8047\n",
      "Epoch 302/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.8473e-10 - accuracy: 0.8263 - val_loss: 2.1816 - val_accuracy: 0.8049\n",
      "Epoch 303/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 6.5977e-10 - accuracy: 0.8272 - val_loss: 2.1815 - val_accuracy: 0.8019\n",
      "Epoch 304/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.9918e-10 - accuracy: 0.8278 - val_loss: 2.2076 - val_accuracy: 0.8078\n",
      "Epoch 305/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.9146e-10 - accuracy: 0.8290 - val_loss: 2.2197 - val_accuracy: 0.8078\n",
      "Epoch 306/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 7.6075e-10 - accuracy: 0.8299 - val_loss: 2.2278 - val_accuracy: 0.8072\n",
      "Epoch 307/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 6.4630e-10 - accuracy: 0.8310 - val_loss: 2.2380 - val_accuracy: 0.8103\n",
      "Epoch 308/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 1.1936e-08 - accuracy: 0.8312 - val_loss: 2.1762 - val_accuracy: 0.7915\n",
      "Epoch 309/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0031 - accuracy: 0.8320 - val_loss: 2.3037 - val_accuracy: 0.8233\n",
      "Epoch 310/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0111 - accuracy: 0.8227 - val_loss: 2.3204 - val_accuracy: 0.7793\n",
      "Epoch 311/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0016 - accuracy: 0.7999 - val_loss: 2.1918 - val_accuracy: 0.7945\n",
      "Epoch 312/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.3885e-04 - accuracy: 0.8069 - val_loss: 2.2217 - val_accuracy: 0.7897\n",
      "Epoch 313/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.7287e-05 - accuracy: 0.8054 - val_loss: 2.2169 - val_accuracy: 0.7926\n",
      "Epoch 314/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.1722e-06 - accuracy: 0.8083 - val_loss: 2.2195 - val_accuracy: 0.7924\n",
      "Epoch 315/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.9724e-07 - accuracy: 0.8074 - val_loss: 2.2205 - val_accuracy: 0.7920\n",
      "Epoch 316/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5766e-07 - accuracy: 0.8073 - val_loss: 2.2218 - val_accuracy: 0.7920\n",
      "Epoch 317/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.9418e-07 - accuracy: 0.8072 - val_loss: 2.2226 - val_accuracy: 0.7920\n",
      "Epoch 318/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.5025e-07 - accuracy: 0.8072 - val_loss: 2.2234 - val_accuracy: 0.7920\n",
      "Epoch 319/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.1541e-07 - accuracy: 0.8073 - val_loss: 2.2240 - val_accuracy: 0.7918\n",
      "Epoch 320/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.8909e-07 - accuracy: 0.8073 - val_loss: 2.2247 - val_accuracy: 0.7918\n",
      "Epoch 321/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.6695e-07 - accuracy: 0.8073 - val_loss: 2.2253 - val_accuracy: 0.7918\n",
      "Epoch 322/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4866e-07 - accuracy: 0.8073 - val_loss: 2.2258 - val_accuracy: 0.7918\n",
      "Epoch 323/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.3287e-07 - accuracy: 0.8075 - val_loss: 2.2265 - val_accuracy: 0.7917\n",
      "Epoch 324/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.1917e-07 - accuracy: 0.8075 - val_loss: 2.2270 - val_accuracy: 0.7918\n",
      "Epoch 325/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0757e-07 - accuracy: 0.8076 - val_loss: 2.2276 - val_accuracy: 0.7917\n",
      "Epoch 326/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 9.6817e-08 - accuracy: 0.8077 - val_loss: 2.2281 - val_accuracy: 0.7920\n",
      "Epoch 327/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 8.7555e-08 - accuracy: 0.8078 - val_loss: 2.2285 - val_accuracy: 0.7918\n",
      "Epoch 328/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 7.9148e-08 - accuracy: 0.8079 - val_loss: 2.2292 - val_accuracy: 0.7920\n",
      "Epoch 329/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 7.1689e-08 - accuracy: 0.8080 - val_loss: 2.2298 - val_accuracy: 0.7920\n",
      "Epoch 330/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 6.4897e-08 - accuracy: 0.8082 - val_loss: 2.2304 - val_accuracy: 0.7920\n",
      "Epoch 331/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 5.8771e-08 - accuracy: 0.8083 - val_loss: 2.2310 - val_accuracy: 0.7920\n",
      "Epoch 332/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.3319e-08 - accuracy: 0.8084 - val_loss: 2.2315 - val_accuracy: 0.7920\n",
      "Epoch 333/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.8337e-08 - accuracy: 0.8087 - val_loss: 2.2321 - val_accuracy: 0.7924\n",
      "Epoch 334/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.3779e-08 - accuracy: 0.8089 - val_loss: 2.2324 - val_accuracy: 0.7924\n",
      "Epoch 335/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.9895e-08 - accuracy: 0.8091 - val_loss: 2.2330 - val_accuracy: 0.7924\n",
      "Epoch 336/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.6334e-08 - accuracy: 0.8093 - val_loss: 2.2335 - val_accuracy: 0.7926\n",
      "Epoch 337/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.3163e-08 - accuracy: 0.8094 - val_loss: 2.2339 - val_accuracy: 0.7926\n",
      "Epoch 338/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.0174e-08 - accuracy: 0.8096 - val_loss: 2.2343 - val_accuracy: 0.7927\n",
      "Epoch 339/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.7515e-08 - accuracy: 0.8098 - val_loss: 2.2348 - val_accuracy: 0.7927\n",
      "Epoch 340/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.5024e-08 - accuracy: 0.8100 - val_loss: 2.2351 - val_accuracy: 0.7931\n",
      "Epoch 341/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.2944e-08 - accuracy: 0.8100 - val_loss: 2.2356 - val_accuracy: 0.7933\n",
      "Epoch 342/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0931e-08 - accuracy: 0.8102 - val_loss: 2.2359 - val_accuracy: 0.7935\n",
      "Epoch 343/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.8978e-08 - accuracy: 0.8104 - val_loss: 2.2363 - val_accuracy: 0.7935\n",
      "Epoch 344/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.7295e-08 - accuracy: 0.8106 - val_loss: 2.2367 - val_accuracy: 0.7938\n",
      "Epoch 345/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.5767e-08 - accuracy: 0.8107 - val_loss: 2.2371 - val_accuracy: 0.7940\n",
      "Epoch 346/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.4407e-08 - accuracy: 0.8110 - val_loss: 2.2374 - val_accuracy: 0.7940\n",
      "Epoch 347/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.3067e-08 - accuracy: 0.8112 - val_loss: 2.2377 - val_accuracy: 0.7940\n",
      "Epoch 348/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.1883e-08 - accuracy: 0.8114 - val_loss: 2.2380 - val_accuracy: 0.7940\n",
      "Epoch 349/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 1.0819e-08 - accuracy: 0.8117 - val_loss: 2.2379 - val_accuracy: 0.7940\n",
      "Epoch 350/500\n",
      "17707/17707 [==============================] - 1s 72us/sample - loss: 9.8763e-09 - accuracy: 0.8118 - val_loss: 2.2386 - val_accuracy: 0.7940\n",
      "Epoch 351/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 9.0011e-09 - accuracy: 0.8120 - val_loss: 2.2389 - val_accuracy: 0.7942\n",
      "Epoch 352/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.1730e-09 - accuracy: 0.8124 - val_loss: 2.2394 - val_accuracy: 0.7947\n",
      "Epoch 353/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.4796e-09 - accuracy: 0.8124 - val_loss: 2.2396 - val_accuracy: 0.7947\n",
      "Epoch 354/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.7525e-09 - accuracy: 0.8126 - val_loss: 2.2398 - val_accuracy: 0.7952\n",
      "Epoch 355/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.1601e-09 - accuracy: 0.8130 - val_loss: 2.2402 - val_accuracy: 0.7952\n",
      "Epoch 356/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.5609e-09 - accuracy: 0.8131 - val_loss: 2.2404 - val_accuracy: 0.7954\n",
      "Epoch 357/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.0156e-09 - accuracy: 0.8132 - val_loss: 2.2408 - val_accuracy: 0.7954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 4.5376e-09 - accuracy: 0.8134 - val_loss: 2.2410 - val_accuracy: 0.7954\n",
      "Epoch 359/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.1740e-09 - accuracy: 0.8135 - val_loss: 2.2412 - val_accuracy: 0.7954\n",
      "Epoch 360/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.8038e-09 - accuracy: 0.8137 - val_loss: 2.2417 - val_accuracy: 0.7958\n",
      "Epoch 361/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 3.3796e-09 - accuracy: 0.8139 - val_loss: 2.2419 - val_accuracy: 0.7961\n",
      "Epoch 362/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 3.0632e-09 - accuracy: 0.8139 - val_loss: 2.2421 - val_accuracy: 0.7960\n",
      "Epoch 363/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.7804e-09 - accuracy: 0.8142 - val_loss: 2.2427 - val_accuracy: 0.7961\n",
      "Epoch 364/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.5179e-09 - accuracy: 0.8144 - val_loss: 2.2433 - val_accuracy: 0.7961\n",
      "Epoch 365/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.2755e-09 - accuracy: 0.8147 - val_loss: 2.2440 - val_accuracy: 0.7961\n",
      "Epoch 366/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0601e-09 - accuracy: 0.8148 - val_loss: 2.2446 - val_accuracy: 0.7967\n",
      "Epoch 367/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.9254e-09 - accuracy: 0.8151 - val_loss: 2.2450 - val_accuracy: 0.7967\n",
      "Epoch 368/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.7033e-09 - accuracy: 0.8152 - val_loss: 2.2456 - val_accuracy: 0.7967\n",
      "Epoch 369/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.5888e-09 - accuracy: 0.8155 - val_loss: 2.2461 - val_accuracy: 0.7969\n",
      "Epoch 370/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.4138e-09 - accuracy: 0.8157 - val_loss: 2.2472 - val_accuracy: 0.7970\n",
      "Epoch 371/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.2791e-09 - accuracy: 0.8160 - val_loss: 2.2481 - val_accuracy: 0.7970\n",
      "Epoch 372/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 1.1310e-09 - accuracy: 0.8163 - val_loss: 2.2493 - val_accuracy: 0.7972\n",
      "Epoch 373/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.8292e-10 - accuracy: 0.8166 - val_loss: 2.2505 - val_accuracy: 0.7974\n",
      "Epoch 374/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.8867e-10 - accuracy: 0.8169 - val_loss: 2.2521 - val_accuracy: 0.7977\n",
      "Epoch 375/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.0115e-10 - accuracy: 0.8172 - val_loss: 2.2536 - val_accuracy: 0.7977\n",
      "Epoch 376/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.9343e-10 - accuracy: 0.8175 - val_loss: 2.2551 - val_accuracy: 0.7983\n",
      "Epoch 377/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.4630e-10 - accuracy: 0.8178 - val_loss: 2.2568 - val_accuracy: 0.7983\n",
      "Epoch 378/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.7898e-10 - accuracy: 0.8181 - val_loss: 2.2590 - val_accuracy: 0.7985\n",
      "Epoch 379/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.4532e-10 - accuracy: 0.8185 - val_loss: 2.2615 - val_accuracy: 0.7995\n",
      "Epoch 380/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.7800e-10 - accuracy: 0.8188 - val_loss: 2.2636 - val_accuracy: 0.7997\n",
      "Epoch 381/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.1067e-10 - accuracy: 0.8192 - val_loss: 2.2660 - val_accuracy: 0.8001\n",
      "Epoch 382/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.9047e-10 - accuracy: 0.8195 - val_loss: 2.2676 - val_accuracy: 0.8004\n",
      "Epoch 383/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.3662e-10 - accuracy: 0.8199 - val_loss: 2.2715 - val_accuracy: 0.8008\n",
      "Epoch 384/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.4335e-10 - accuracy: 0.8203 - val_loss: 2.2732 - val_accuracy: 0.8013\n",
      "Epoch 385/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.7603e-10 - accuracy: 0.8207 - val_loss: 2.2771 - val_accuracy: 0.8024\n",
      "Epoch 386/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.6256e-10 - accuracy: 0.8213 - val_loss: 2.2797 - val_accuracy: 0.8028\n",
      "Epoch 387/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0870e-10 - accuracy: 0.8217 - val_loss: 2.2842 - val_accuracy: 0.8035\n",
      "Epoch 388/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0870e-10 - accuracy: 0.8223 - val_loss: 2.2869 - val_accuracy: 0.8036\n",
      "Epoch 389/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.7504e-10 - accuracy: 0.8227 - val_loss: 2.2926 - val_accuracy: 0.8044\n",
      "Epoch 390/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.8177e-10 - accuracy: 0.8235 - val_loss: 2.2962 - val_accuracy: 0.8047\n",
      "Epoch 391/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.7504e-10 - accuracy: 0.8241 - val_loss: 2.3014 - val_accuracy: 0.8053\n",
      "Epoch 392/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 1.6831e-10 - accuracy: 0.8246 - val_loss: 2.3065 - val_accuracy: 0.8056\n",
      "Epoch 393/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.9524e-10 - accuracy: 0.8253 - val_loss: 2.3111 - val_accuracy: 0.8060\n",
      "Epoch 394/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6831e-10 - accuracy: 0.8259 - val_loss: 2.3153 - val_accuracy: 0.8063\n",
      "Epoch 395/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.8851e-10 - accuracy: 0.8265 - val_loss: 2.3218 - val_accuracy: 0.8074\n",
      "Epoch 396/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.8851e-10 - accuracy: 0.8276 - val_loss: 2.3266 - val_accuracy: 0.8078\n",
      "Epoch 397/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.0197e-10 - accuracy: 0.8281 - val_loss: 2.3337 - val_accuracy: 0.8087\n",
      "Epoch 398/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.0197e-10 - accuracy: 0.8293 - val_loss: 2.3407 - val_accuracy: 0.8092\n",
      "Epoch 399/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.0870e-10 - accuracy: 0.8302 - val_loss: 2.3501 - val_accuracy: 0.8099\n",
      "Epoch 400/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.0870e-10 - accuracy: 0.8315 - val_loss: 2.3591 - val_accuracy: 0.8108\n",
      "Epoch 401/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.6256e-10 - accuracy: 0.8326 - val_loss: 2.3720 - val_accuracy: 0.8110\n",
      "Epoch 402/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.9622e-10 - accuracy: 0.8335 - val_loss: 2.3845 - val_accuracy: 0.8138\n",
      "Epoch 403/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5681e-10 - accuracy: 0.8349 - val_loss: 2.3949 - val_accuracy: 0.8142\n",
      "Epoch 404/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.8949e-10 - accuracy: 0.8363 - val_loss: 2.4091 - val_accuracy: 0.8156\n",
      "Epoch 405/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.7028e-10 - accuracy: 0.8376 - val_loss: 2.4335 - val_accuracy: 0.8212\n",
      "Epoch 406/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.9146e-10 - accuracy: 0.8384 - val_loss: 2.4353 - val_accuracy: 0.8190\n",
      "Epoch 407/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.9047e-10 - accuracy: 0.8407 - val_loss: 2.4546 - val_accuracy: 0.8203\n",
      "Epoch 408/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.6075e-10 - accuracy: 0.8425 - val_loss: 2.4596 - val_accuracy: 0.8197\n",
      "Epoch 409/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 6.0591e-10 - accuracy: 0.8430 - val_loss: 2.4803 - val_accuracy: 0.8215\n",
      "Epoch 410/500\n",
      "17707/17707 [==============================] - 1s 69us/sample - loss: 6.3144e-04 - accuracy: 0.8457 - val_loss: 2.5759 - val_accuracy: 0.8364\n",
      "Epoch 411/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 0.0038 - accuracy: 0.8411 - val_loss: 2.3673 - val_accuracy: 0.8137\n",
      "Epoch 412/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 0.0076 - accuracy: 0.8319 - val_loss: 2.7121 - val_accuracy: 0.7784\n",
      "Epoch 413/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0067 - accuracy: 0.8271 - val_loss: 2.2741 - val_accuracy: 0.8094\n",
      "Epoch 414/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 0.0026 - accuracy: 0.8226 - val_loss: 2.1812 - val_accuracy: 0.8028\n",
      "Epoch 415/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.1708e-05 - accuracy: 0.8262 - val_loss: 2.1995 - val_accuracy: 0.8029\n",
      "Epoch 416/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 7.2240e-07 - accuracy: 0.8254 - val_loss: 2.1990 - val_accuracy: 0.8033\n",
      "Epoch 417/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.4758e-07 - accuracy: 0.8257 - val_loss: 2.1985 - val_accuracy: 0.8033\n",
      "Epoch 418/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.9305e-07 - accuracy: 0.8257 - val_loss: 2.1982 - val_accuracy: 0.8033\n",
      "Epoch 419/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.5921e-07 - accuracy: 0.8258 - val_loss: 2.1979 - val_accuracy: 0.8035\n",
      "Epoch 420/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.3466e-07 - accuracy: 0.8258 - val_loss: 2.1977 - val_accuracy: 0.8035\n",
      "Epoch 421/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.1559e-07 - accuracy: 0.8259 - val_loss: 2.1974 - val_accuracy: 0.8035\n",
      "Epoch 422/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.0206e-07 - accuracy: 0.8260 - val_loss: 2.1973 - val_accuracy: 0.8035\n",
      "Epoch 423/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 8.8502e-08 - accuracy: 0.8260 - val_loss: 2.1971 - val_accuracy: 0.8035\n",
      "Epoch 424/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.8547e-08 - accuracy: 0.8260 - val_loss: 2.1968 - val_accuracy: 0.8035\n",
      "Epoch 425/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.9769e-08 - accuracy: 0.8260 - val_loss: 2.1967 - val_accuracy: 0.8035\n",
      "Epoch 426/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.2048e-08 - accuracy: 0.8260 - val_loss: 2.1965 - val_accuracy: 0.8035\n",
      "Epoch 427/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.5229e-08 - accuracy: 0.8260 - val_loss: 2.1962 - val_accuracy: 0.8035\n",
      "Epoch 428/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 4.9568e-08 - accuracy: 0.8260 - val_loss: 2.1960 - val_accuracy: 0.8035\n",
      "Epoch 429/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 4.4317e-08 - accuracy: 0.8260 - val_loss: 2.1960 - val_accuracy: 0.8035\n",
      "Epoch 430/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 3.9881e-08 - accuracy: 0.8260 - val_loss: 2.1958 - val_accuracy: 0.8033\n",
      "Epoch 431/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.5741e-08 - accuracy: 0.8261 - val_loss: 2.1957 - val_accuracy: 0.8033\n",
      "Epoch 432/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.2038e-08 - accuracy: 0.8261 - val_loss: 2.1956 - val_accuracy: 0.8033\n",
      "Epoch 433/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.8989e-08 - accuracy: 0.8261 - val_loss: 2.1953 - val_accuracy: 0.8031\n",
      "Epoch 434/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.6114e-08 - accuracy: 0.8261 - val_loss: 2.1953 - val_accuracy: 0.8031\n",
      "Epoch 435/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.3603e-08 - accuracy: 0.8260 - val_loss: 2.1950 - val_accuracy: 0.8031\n",
      "Epoch 436/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.1321e-08 - accuracy: 0.8261 - val_loss: 2.1950 - val_accuracy: 0.8033\n",
      "Epoch 437/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.9375e-08 - accuracy: 0.8261 - val_loss: 2.1947 - val_accuracy: 0.8033\n",
      "Epoch 438/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.7591e-08 - accuracy: 0.8260 - val_loss: 2.1944 - val_accuracy: 0.8033\n",
      "Epoch 439/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6124e-08 - accuracy: 0.8261 - val_loss: 2.1944 - val_accuracy: 0.8033\n",
      "Epoch 440/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.4683e-08 - accuracy: 0.8260 - val_loss: 2.1943 - val_accuracy: 0.8033\n",
      "Epoch 441/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.3343e-08 - accuracy: 0.8260 - val_loss: 2.1942 - val_accuracy: 0.8033\n",
      "Epoch 442/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2098e-08 - accuracy: 0.8261 - val_loss: 2.1939 - val_accuracy: 0.8033\n",
      "Epoch 443/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.1102e-08 - accuracy: 0.8261 - val_loss: 2.1938 - val_accuracy: 0.8033\n",
      "Epoch 444/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.0253e-08 - accuracy: 0.8261 - val_loss: 2.1938 - val_accuracy: 0.8033\n",
      "Epoch 445/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 9.4723e-09 - accuracy: 0.8260 - val_loss: 2.1937 - val_accuracy: 0.8033\n",
      "Epoch 446/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.6577e-09 - accuracy: 0.8260 - val_loss: 2.1936 - val_accuracy: 0.8033\n",
      "Epoch 447/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.9912e-09 - accuracy: 0.8261 - val_loss: 2.1937 - val_accuracy: 0.8036\n",
      "Epoch 448/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 7.3651e-09 - accuracy: 0.8261 - val_loss: 2.1937 - val_accuracy: 0.8036\n",
      "Epoch 449/500\n",
      "17707/17707 [==============================] - 1s 68us/sample - loss: 6.8333e-09 - accuracy: 0.8262 - val_loss: 2.1937 - val_accuracy: 0.8036\n",
      "Epoch 450/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 6.2678e-09 - accuracy: 0.8262 - val_loss: 2.1939 - val_accuracy: 0.8038\n",
      "Epoch 451/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 5.8100e-09 - accuracy: 0.8262 - val_loss: 2.1940 - val_accuracy: 0.8038\n",
      "Epoch 452/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 5.3522e-09 - accuracy: 0.8262 - val_loss: 2.1941 - val_accuracy: 0.8038\n",
      "Epoch 453/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 4.9617e-09 - accuracy: 0.8263 - val_loss: 2.1942 - val_accuracy: 0.8036\n",
      "Epoch 454/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 4.5982e-09 - accuracy: 0.8264 - val_loss: 2.1947 - val_accuracy: 0.8036\n",
      "Epoch 455/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.2683e-09 - accuracy: 0.8264 - val_loss: 2.1948 - val_accuracy: 0.8036\n",
      "Epoch 456/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.9451e-09 - accuracy: 0.8265 - val_loss: 2.1952 - val_accuracy: 0.8036\n",
      "Epoch 457/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 3.6960e-09 - accuracy: 0.8265 - val_loss: 2.1955 - val_accuracy: 0.8036\n",
      "Epoch 458/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.3864e-09 - accuracy: 0.8265 - val_loss: 2.1961 - val_accuracy: 0.8036\n",
      "Epoch 459/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.1844e-09 - accuracy: 0.8267 - val_loss: 2.1966 - val_accuracy: 0.8036\n",
      "Epoch 460/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.8949e-09 - accuracy: 0.8267 - val_loss: 2.1971 - val_accuracy: 0.8036\n",
      "Epoch 461/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.6795e-09 - accuracy: 0.8267 - val_loss: 2.1978 - val_accuracy: 0.8036\n",
      "Epoch 462/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.4708e-09 - accuracy: 0.8269 - val_loss: 2.1986 - val_accuracy: 0.8038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.3563e-09 - accuracy: 0.8270 - val_loss: 2.1991 - val_accuracy: 0.8038\n",
      "Epoch 464/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.1476e-09 - accuracy: 0.8270 - val_loss: 2.2003 - val_accuracy: 0.8038\n",
      "Epoch 465/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.9793e-09 - accuracy: 0.8272 - val_loss: 2.2010 - val_accuracy: 0.8038\n",
      "Epoch 466/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.8514e-09 - accuracy: 0.8272 - val_loss: 2.2020 - val_accuracy: 0.8040\n",
      "Epoch 467/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.6898e-09 - accuracy: 0.8273 - val_loss: 2.2027 - val_accuracy: 0.8040\n",
      "Epoch 468/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.5686e-09 - accuracy: 0.8275 - val_loss: 2.2043 - val_accuracy: 0.8042\n",
      "Epoch 469/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.4542e-09 - accuracy: 0.8275 - val_loss: 2.2054 - val_accuracy: 0.8044\n",
      "Epoch 470/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.3599e-09 - accuracy: 0.8277 - val_loss: 2.2067 - val_accuracy: 0.8045\n",
      "Epoch 471/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.2455e-09 - accuracy: 0.8280 - val_loss: 2.2082 - val_accuracy: 0.8047\n",
      "Epoch 472/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.0974e-09 - accuracy: 0.8279 - val_loss: 2.2100 - val_accuracy: 0.8047\n",
      "Epoch 473/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.0772e-09 - accuracy: 0.8283 - val_loss: 2.2118 - val_accuracy: 0.8047\n",
      "Epoch 474/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.9638e-10 - accuracy: 0.8283 - val_loss: 2.2137 - val_accuracy: 0.8049\n",
      "Epoch 475/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 9.0213e-10 - accuracy: 0.8285 - val_loss: 2.2155 - val_accuracy: 0.8053\n",
      "Epoch 476/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 8.2134e-10 - accuracy: 0.8289 - val_loss: 2.2172 - val_accuracy: 0.8056\n",
      "Epoch 477/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 7.7422e-10 - accuracy: 0.8289 - val_loss: 2.2200 - val_accuracy: 0.8058\n",
      "Epoch 478/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.8670e-10 - accuracy: 0.8294 - val_loss: 2.2225 - val_accuracy: 0.8060\n",
      "Epoch 479/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 6.3284e-10 - accuracy: 0.8296 - val_loss: 2.2256 - val_accuracy: 0.8063\n",
      "Epoch 480/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 6.1264e-10 - accuracy: 0.8299 - val_loss: 2.2273 - val_accuracy: 0.8063\n",
      "Epoch 481/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 5.2512e-10 - accuracy: 0.8302 - val_loss: 2.2299 - val_accuracy: 0.8063\n",
      "Epoch 482/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.7800e-10 - accuracy: 0.8305 - val_loss: 2.2328 - val_accuracy: 0.8063\n",
      "Epoch 483/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.5107e-10 - accuracy: 0.8308 - val_loss: 2.2351 - val_accuracy: 0.8067\n",
      "Epoch 484/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 4.1067e-10 - accuracy: 0.8311 - val_loss: 2.2392 - val_accuracy: 0.8070\n",
      "Epoch 485/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 4.1067e-10 - accuracy: 0.8315 - val_loss: 2.2405 - val_accuracy: 0.8074\n",
      "Epoch 486/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 3.2315e-10 - accuracy: 0.8319 - val_loss: 2.2455 - val_accuracy: 0.8079\n",
      "Epoch 487/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 2.9622e-10 - accuracy: 0.8326 - val_loss: 2.2497 - val_accuracy: 0.8085\n",
      "Epoch 488/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.6929e-10 - accuracy: 0.8329 - val_loss: 2.2533 - val_accuracy: 0.8090\n",
      "Epoch 489/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.2890e-10 - accuracy: 0.8333 - val_loss: 2.2576 - val_accuracy: 0.8095\n",
      "Epoch 490/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 2.2217e-10 - accuracy: 0.8339 - val_loss: 2.2613 - val_accuracy: 0.8099\n",
      "Epoch 491/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.8177e-10 - accuracy: 0.8345 - val_loss: 2.2663 - val_accuracy: 0.8110\n",
      "Epoch 492/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.9524e-10 - accuracy: 0.8352 - val_loss: 2.2708 - val_accuracy: 0.8117\n",
      "Epoch 493/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6831e-10 - accuracy: 0.8358 - val_loss: 2.2768 - val_accuracy: 0.8126\n",
      "Epoch 494/500\n",
      "17707/17707 [==============================] - 1s 70us/sample - loss: 1.6158e-10 - accuracy: 0.8362 - val_loss: 2.2816 - val_accuracy: 0.8124\n",
      "Epoch 495/500\n",
      "17707/17707 [==============================] - 1s 65us/sample - loss: 1.6831e-10 - accuracy: 0.8367 - val_loss: 2.2885 - val_accuracy: 0.8126\n",
      "Epoch 496/500\n",
      "17707/17707 [==============================] - 1s 64us/sample - loss: 1.6831e-10 - accuracy: 0.8374 - val_loss: 2.2944 - val_accuracy: 0.8128\n",
      "Epoch 497/500\n",
      "17707/17707 [==============================] - 1s 63us/sample - loss: 1.4138e-10 - accuracy: 0.8380 - val_loss: 2.3038 - val_accuracy: 0.8131\n",
      "Epoch 498/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 1.7504e-10 - accuracy: 0.8386 - val_loss: 2.3106 - val_accuracy: 0.8129\n",
      "Epoch 499/500\n",
      "17707/17707 [==============================] - 1s 67us/sample - loss: 1.8851e-10 - accuracy: 0.8387 - val_loss: 2.3245 - val_accuracy: 0.8149\n",
      "Epoch 500/500\n",
      "17707/17707 [==============================] - 1s 66us/sample - loss: 2.3563e-10 - accuracy: 0.8398 - val_loss: 2.3284 - val_accuracy: 0.8140\n",
      "WARNING:tensorflow:From /home/khanhi83/anaconda3/envs/PY3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    local_dir = './data'\n",
    "\n",
    "    compute_features = not os.path.exists(f'{local_dir}/feature_data.csv')\n",
    "    model_type = \"mlp\" #\"{knn\", \"mlp\", \"rf\"}  \n",
    "\n",
    "    if compute_features:\n",
    "        # download the file\n",
    "        path_to_downloaded_zip_file = download_file(\n",
    "            'https://www.fire.tc.faa.gov/zip/MasterModelVersion3DDeliverable.zip',\n",
    "            local_dir)\n",
    "        # unzip the file\n",
    "        path_to_file = unzip_file(path_to_downloaded_zip_file, local_dir)\n",
    "\n",
    "        # load the file into a Pandas dataframe\n",
    "        df = load_data(path_to_file)\n",
    "\n",
    "        # save preprocessed data to save time for future runs\n",
    "        df.to_csv(f'{local_dir}/feature_data.csv')\n",
    "    else:\n",
    "        # don't go through the hassle of preprocessing if we already have the preprocessed data saved\n",
    "        df = pd.read_csv(f'{local_dir}/feature_data.csv')\n",
    "\n",
    "    count_of_no_text = len(df[df[TEXT_COLUMN].isnull()])\n",
    "    df = df.dropna(subset=[TEXT_COLUMN])\n",
    "#     _LOGGER.info(f\"Dropped {count_of_no_text} records because {TEXT_COLUMN} was null or NaN\")\n",
    "    print(\"Dropped {0} records because {1} was null or NaN\".format(count_of_no_text, TEXT_COLUMN))\n",
    "\n",
    "    count_of_null_labels = len(df[df[LABEL_COLUMN].isnull()])\n",
    "    df = df.dropna(subset=[LABEL_COLUMN])\n",
    "#     _LOGGER.info(f\"Dropped {count_of_null_labels} records because {LABEL_COLUMN} was null or NaN\")\n",
    "    print(\"Dropped {0} records because {1} was null or NaN\".format(count_of_null_labels, LABEL_COLUMN))\n",
    "\n",
    "    # create a sparse feature matrix of size n x m,\n",
    "    # where n = number of documents, m = number of words in vocabulary\n",
    "    feature_matrix, feature_names = vectorize(df, min_df=0.001)\n",
    "\n",
    "    labels, label_mapping = extract_and_encode_labels(df)\n",
    "    num_labels = len(label_mapping)\n",
    "    num_features = feature_matrix.shape[1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_matrix, labels, test_size=0.05, random_state=1)\n",
    "\n",
    "#     _LOGGER.info(f\"Training on {X_train.shape[0]} samples, validating on {X_test.shape[0]} samples.\")\n",
    "    print(\"Training on {0} sample, validating on {1} samples\".format(X_train.shape[0], X_test.shape[0]))\n",
    "#     _LOGGER.info(f\"Number of features: {num_features}\")\n",
    "    print(\"Number of features: {0}\".format(num_features))\n",
    "\n",
    "    if model_type == \"mlp\":\n",
    "        labels = one_hot(np.array(labels), len(label_mapping))\n",
    "        inputs = keras.Input(shape=(num_features,))\n",
    "        layer_1 = layers.Dense(8192, activation=ReLU())(inputs)\n",
    "        layer_2 = layers.Dense(2048, activation=ReLU())(layer_1)\n",
    "        layer_3 = layers.Dense(512, activation=ReLU())(layer_2)\n",
    "        layer_4 = layers.Dense(128, activation=ReLU())(layer_3)\n",
    "        layer_5 = layers.Dense(32, activation=ReLU())(layer_4)\n",
    "        layer_6 = layers.Dense(8, activation=ReLU())(layer_5)\n",
    "        outputs = layers.Dense(num_labels, activation=\"softmax\")(layer_6)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#         _LOGGER.info(model.summary())\n",
    "        print(model.summary())\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adamax(),  # Optimizer\n",
    "            loss=keras.losses.CategoricalCrossentropy(),  # Loss function to minimize\n",
    "            metrics=[keras.metrics.Accuracy()]  # List of metrics to monitor\n",
    "        )\n",
    "#         print(\"X_Train:\", X_train.shape, \" y_Train:\", y_train.shape)\n",
    "        #Changed\n",
    "        y_train = to_categorical(y_train)\n",
    "        y_test = to_categorical(y_test)\n",
    "        #Changed\n",
    "        model.fit(X_train, y_train,\n",
    "                  validation_data=(X_test, y_test), shuffle=True, epochs=500, batch_size=128,\n",
    "                  callbacks=[CSVLogger('./results.csv')])\n",
    "        model.save('model')\n",
    "    elif model_type == \"rf\":\n",
    "        rf = RandomForestClassifier(n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        training_acc = rf.score(X_train, y_train)\n",
    "        validation_acc = rf.score(X_test, y_test)\n",
    "#         _LOGGER.info(f\"Training accuracy with Random Forest: {training_acc}\")\n",
    "        print(\"Training accuracy with Random Forest: {0}\".format(training_acc))\n",
    "#         _LOGGER.info(f\"Validation accuracy with Random Forest: {validation_acc}\")\n",
    "        print(\"Validation accuracy with Random Forest: {0}\".format(validation_acc))\n",
    "    elif model_type == \"knn\":\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "        knn.fit(X_train, y_train)\n",
    "        training_acc = knn.score(X_train, y_train)\n",
    "        validation_acc = knn.score(X_test, y_test)\n",
    "#         _LOGGER.info(f\"Training accuracy with kNN: {training_acc}\")\n",
    "        print(\"Training accuracy with kNN: {0}\".format(training_acc))\n",
    "#         _LOGGER.info(f\"Validation accuracy with kNN: {validation_acc}\")\n",
    "        print(\"Validation accuracy with kNN: {0}\".format(validation_acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/home/khanhi83/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,5,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,87,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,117,118,119,121,122,123,124,125,126,127,128,130,131,132,145,146,148,215,224) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "  interactivity=interactivity, compiler=compiler, result=result)\n",
    "Dropped 3198 records because Text was null or NaN\n",
    "Dropped 4438 records because False Warning was null or NaN\n",
    "Converting text to feature matrix\n",
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "Model: \"model_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         [(None, 2285)]            0         \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 8192)              18726912  \n",
    "_________________________________________________________________\n",
    "dense_8 (Dense)              (None, 2048)              16779264  \n",
    "_________________________________________________________________\n",
    "dense_9 (Dense)              (None, 512)               1049088   \n",
    "_________________________________________________________________\n",
    "dense_10 (Dense)             (None, 128)               65664     \n",
    "_________________________________________________________________\n",
    "dense_11 (Dense)             (None, 32)                4128      \n",
    "_________________________________________________________________\n",
    "dense_12 (Dense)             (None, 8)                 264       \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 6)                 54        \n",
    "=================================================================\n",
    "Total params: 36,625,374\n",
    "Trainable params: 36,625,374\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "Train on 17707 samples, validate on 932 samples\n",
    "Epoch 1/200\n",
    "17707/17707 [==============================] - 23s 1ms/sample - loss: 1.4150 - accuracy: 0.0000e+00 - val_loss: 0.9210 - val_accuracy: 0.0000e+00\n",
    "Epoch 2/200\n",
    "17707/17707 [==============================] - 21s 1ms/sample - loss: 0.3722 - accuracy: 0.0143 - val_loss: 0.3149 - val_accuracy: 0.0023\n",
    "Epoch 3/200\n",
    "17707/17707 [==============================] - 21s 1ms/sample - loss: 0.1743 - accuracy: 0.0360 - val_loss: 0.3176 - val_accuracy: 0.0304\n",
    "Epoch 4/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.1284 - accuracy: 0.0615 - val_loss: 0.3605 - val_accuracy: 0.0899\n",
    "Epoch 5/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.1000 - accuracy: 0.1414 - val_loss: 0.4587 - val_accuracy: 0.1947\n",
    "Epoch 6/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0823 - accuracy: 0.2460 - val_loss: 0.5036 - val_accuracy: 0.2786\n",
    "Epoch 7/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0699 - accuracy: 0.3137 - val_loss: 0.6804 - val_accuracy: 0.3389\n",
    "Epoch 8/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0560 - accuracy: 0.3642 - val_loss: 0.7671 - val_accuracy: 0.4054\n",
    "Epoch 9/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0442 - accuracy: 0.4358 - val_loss: 0.9645 - val_accuracy: 0.4515\n",
    "Epoch 10/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0275 - accuracy: 0.4755 - val_loss: 1.1239 - val_accuracy: 0.4937\n",
    "Epoch 11/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0159 - accuracy: 0.5119 - val_loss: 1.3274 - val_accuracy: 0.4950\n",
    "Epoch 12/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0115 - accuracy: 0.5280 - val_loss: 1.4747 - val_accuracy: 0.5299\n",
    "Epoch 13/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0066 - accuracy: 0.5471 - val_loss: 1.6228 - val_accuracy: 0.5477\n",
    "Epoch 14/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0040 - accuracy: 0.5597 - val_loss: 1.6750 - val_accuracy: 0.5445\n",
    "Epoch 15/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0044 - accuracy: 0.5728 - val_loss: 1.9112 - val_accuracy: 0.5696\n",
    "Epoch 16/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0032 - accuracy: 0.5788 - val_loss: 1.8407 - val_accuracy: 0.5519\n",
    "Epoch 17/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0029 - accuracy: 0.5792 - val_loss: 1.9215 - val_accuracy: 0.5617\n",
    "Epoch 18/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0019 - accuracy: 0.5771 - val_loss: 1.8772 - val_accuracy: 0.5588\n",
    "Epoch 19/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0016 - accuracy: 0.5818 - val_loss: 2.0288 - val_accuracy: 0.5676\n",
    "Epoch 20/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0015 - accuracy: 0.5926 - val_loss: 2.1321 - val_accuracy: 0.5805\n",
    "Epoch 21/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0012 - accuracy: 0.5903 - val_loss: 2.1226 - val_accuracy: 0.5765\n",
    "Epoch 22/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.0182e-04 - accuracy: 0.5997 - val_loss: 2.1272 - val_accuracy: 0.5794\n",
    "Epoch 23/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.2876e-04 - accuracy: 0.6025 - val_loss: 2.3240 - val_accuracy: 0.5853\n",
    "Epoch 24/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0015 - accuracy: 0.6043 - val_loss: 2.2679 - val_accuracy: 0.5950\n",
    "Epoch 25/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0010 - accuracy: 0.6122 - val_loss: 2.3546 - val_accuracy: 0.5969\n",
    "Epoch 26/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0017 - accuracy: 0.6151 - val_loss: 2.3396 - val_accuracy: 0.6059\n",
    "Epoch 27/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0014 - accuracy: 0.6215 - val_loss: 2.3133 - val_accuracy: 0.5975\n",
    "Epoch 28/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0012 - accuracy: 0.6211 - val_loss: 2.5287 - val_accuracy: 0.6109\n",
    "Epoch 29/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.3126e-04 - accuracy: 0.6211 - val_loss: 2.3866 - val_accuracy: 0.6014\n",
    "Epoch 30/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.9634e-04 - accuracy: 0.6271 - val_loss: 2.4712 - val_accuracy: 0.6132\n",
    "Epoch 31/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 4.5758e-04 - accuracy: 0.6306 - val_loss: 2.4926 - val_accuracy: 0.6093\n",
    "Epoch 32/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.4534e-04 - accuracy: 0.6300 - val_loss: 2.5364 - val_accuracy: 0.6109\n",
    "Epoch 33/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.5584e-04 - accuracy: 0.6338 - val_loss: 2.5000 - val_accuracy: 0.6137\n",
    "Epoch 34/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0017 - accuracy: 0.6241 - val_loss: 2.8836 - val_accuracy: 0.6440\n",
    "Epoch 35/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0035 - accuracy: 0.6295 - val_loss: 2.5241 - val_accuracy: 0.6148\n",
    "Epoch 36/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.9955e-04 - accuracy: 0.6252 - val_loss: 2.5342 - val_accuracy: 0.6046\n",
    "Epoch 37/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.0255e-04 - accuracy: 0.6235 - val_loss: 2.4824 - val_accuracy: 0.6075\n",
    "Epoch 38/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.1674e-04 - accuracy: 0.6268 - val_loss: 2.5254 - val_accuracy: 0.6096\n",
    "Epoch 39/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.8860e-04 - accuracy: 0.6290 - val_loss: 2.5533 - val_accuracy: 0.6103\n",
    "Epoch 40/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.7277e-04 - accuracy: 0.6305 - val_loss: 2.6051 - val_accuracy: 0.6141\n",
    "Epoch 41/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.5573e-04 - accuracy: 0.6326 - val_loss: 2.6354 - val_accuracy: 0.6159\n",
    "Epoch 42/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4272e-04 - accuracy: 0.6345 - val_loss: 2.6866 - val_accuracy: 0.6200\n",
    "Epoch 43/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3079e-04 - accuracy: 0.6368 - val_loss: 2.7114 - val_accuracy: 0.6187\n",
    "Epoch 44/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2389e-04 - accuracy: 0.6416 - val_loss: 2.7729 - val_accuracy: 0.6254\n",
    "Epoch 45/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 1.1437e-04 - accuracy: 0.6433 - val_loss: 2.8304 - val_accuracy: 0.6270\n",
    "Epoch 46/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4042e-04 - accuracy: 0.6533 - val_loss: 2.7734 - val_accuracy: 0.6153\n",
    "Epoch 47/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.8073e-04 - accuracy: 0.6546 - val_loss: 3.0387 - val_accuracy: 0.6495\n",
    "Epoch 48/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.9365e-04 - accuracy: 0.6580 - val_loss: 3.0219 - val_accuracy: 0.6427\n",
    "Epoch 49/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0023 - accuracy: 0.6498 - val_loss: 3.0022 - val_accuracy: 0.6509\n",
    "Epoch 50/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0017 - accuracy: 0.6505 - val_loss: 2.8578 - val_accuracy: 0.6186\n",
    "Epoch 51/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.9768e-04 - accuracy: 0.6414 - val_loss: 2.8186 - val_accuracy: 0.6164\n",
    "Epoch 52/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.0440e-05 - accuracy: 0.6401 - val_loss: 2.8520 - val_accuracy: 0.6209\n",
    "Epoch 53/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.4216e-05 - accuracy: 0.6428 - val_loss: 2.8699 - val_accuracy: 0.6220\n",
    "Epoch 54/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.0284e-05 - accuracy: 0.6453 - val_loss: 2.8923 - val_accuracy: 0.6237\n",
    "Epoch 55/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.7129e-05 - accuracy: 0.6470 - val_loss: 2.9173 - val_accuracy: 0.6259\n",
    "Epoch 56/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4437e-05 - accuracy: 0.6493 - val_loss: 2.9416 - val_accuracy: 0.6270\n",
    "Epoch 57/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2049e-05 - accuracy: 0.6530 - val_loss: 2.9664 - val_accuracy: 0.6296\n",
    "Epoch 58/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0006e-05 - accuracy: 0.6544 - val_loss: 3.0012 - val_accuracy: 0.6339\n",
    "Epoch 59/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.0733e-06 - accuracy: 0.6577 - val_loss: 3.0306 - val_accuracy: 0.6361\n",
    "Epoch 60/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.3958e-06 - accuracy: 0.6627 - val_loss: 3.0657 - val_accuracy: 0.6397\n",
    "Epoch 61/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.1267e-06 - accuracy: 0.6665 - val_loss: 3.1096 - val_accuracy: 0.6434\n",
    "Epoch 62/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.3071e-06 - accuracy: 0.6717 - val_loss: 3.1489 - val_accuracy: 0.6486\n",
    "Epoch 63/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.0519e-06 - accuracy: 0.6747 - val_loss: 3.1842 - val_accuracy: 0.6527\n",
    "Epoch 64/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3886e-05 - accuracy: 0.6886 - val_loss: 3.2555 - val_accuracy: 0.6617\n",
    "Epoch 65/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0026 - accuracy: 0.6769 - val_loss: 3.0588 - val_accuracy: 0.6477\n",
    "Epoch 66/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.6556e-04 - accuracy: 0.6598 - val_loss: 3.0826 - val_accuracy: 0.6465\n",
    "Epoch 67/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.7393e-04 - accuracy: 0.6490 - val_loss: 2.9321 - val_accuracy: 0.6311\n",
    "Epoch 68/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.8850e-05 - accuracy: 0.6543 - val_loss: 2.9670 - val_accuracy: 0.6348\n",
    "Epoch 69/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.6568e-06 - accuracy: 0.6557 - val_loss: 2.9885 - val_accuracy: 0.6372\n",
    "Epoch 70/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.1857e-06 - accuracy: 0.6603 - val_loss: 3.0026 - val_accuracy: 0.6391\n",
    "Epoch 71/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.9654e-06 - accuracy: 0.6622 - val_loss: 3.0144 - val_accuracy: 0.6398\n",
    "Epoch 72/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.0051e-06 - accuracy: 0.6635 - val_loss: 3.0308 - val_accuracy: 0.6427\n",
    "Epoch 73/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.2040e-06 - accuracy: 0.6667 - val_loss: 3.0433 - val_accuracy: 0.6440\n",
    "Epoch 74/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 3.6052e-06 - accuracy: 0.6686 - val_loss: 3.0571 - val_accuracy: 0.6452\n",
    "Epoch 75/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.0645e-06 - accuracy: 0.6709 - val_loss: 3.0771 - val_accuracy: 0.6475\n",
    "Epoch 76/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.5762e-06 - accuracy: 0.6733 - val_loss: 3.0965 - val_accuracy: 0.6491\n",
    "Epoch 77/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.1639e-06 - accuracy: 0.6759 - val_loss: 3.1221 - val_accuracy: 0.6540\n",
    "Epoch 78/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.7895e-06 - accuracy: 0.6803 - val_loss: 3.1421 - val_accuracy: 0.6559\n",
    "Epoch 79/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4851e-06 - accuracy: 0.6823 - val_loss: 3.1696 - val_accuracy: 0.6592\n",
    "Epoch 80/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2142e-06 - accuracy: 0.6877 - val_loss: 3.1955 - val_accuracy: 0.6624\n",
    "Epoch 81/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.9492e-07 - accuracy: 0.6903 - val_loss: 3.2292 - val_accuracy: 0.6677\n",
    "Epoch 82/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.0725e-07 - accuracy: 0.6928 - val_loss: 3.2590 - val_accuracy: 0.6727\n",
    "Epoch 83/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.3853e-07 - accuracy: 0.7008 - val_loss: 3.2905 - val_accuracy: 0.6753\n",
    "Epoch 84/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.1452e-07 - accuracy: 0.7026 - val_loss: 3.3332 - val_accuracy: 0.6812\n",
    "Epoch 85/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.1269e-07 - accuracy: 0.7081 - val_loss: 3.3570 - val_accuracy: 0.6849\n",
    "Epoch 86/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.3819e-07 - accuracy: 0.7145 - val_loss: 3.4000 - val_accuracy: 0.6897\n",
    "Epoch 87/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.8479e-07 - accuracy: 0.7184 - val_loss: 3.4330 - val_accuracy: 0.6940\n",
    "Epoch 88/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.6479e-05 - accuracy: 0.7220 - val_loss: 3.4322 - val_accuracy: 0.6922\n",
    "Epoch 89/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 5.3481e-04 - accuracy: 0.7163 - val_loss: 3.3538 - val_accuracy: 0.6786\n",
    "Epoch 90/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.7037e-04 - accuracy: 0.7150 - val_loss: 3.3997 - val_accuracy: 0.6890\n",
    "Epoch 91/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0039 - accuracy: 0.7198 - val_loss: 3.2467 - val_accuracy: 0.6888\n",
    "Epoch 92/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.3487e-04 - accuracy: 0.7072 - val_loss: 3.1163 - val_accuracy: 0.6781\n",
    "Epoch 93/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.4818e-06 - accuracy: 0.7032 - val_loss: 3.1275 - val_accuracy: 0.6810\n",
    "Epoch 94/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.5704e-06 - accuracy: 0.7042 - val_loss: 3.1413 - val_accuracy: 0.6815\n",
    "Epoch 95/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2467e-06 - accuracy: 0.7048 - val_loss: 3.1527 - val_accuracy: 0.6819\n",
    "Epoch 96/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0487e-06 - accuracy: 0.7052 - val_loss: 3.1643 - val_accuracy: 0.6822\n",
    "Epoch 97/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.0087e-07 - accuracy: 0.7059 - val_loss: 3.1746 - val_accuracy: 0.6828\n",
    "Epoch 98/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.9197e-07 - accuracy: 0.7066 - val_loss: 3.1861 - val_accuracy: 0.6835\n",
    "Epoch 99/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.1044e-07 - accuracy: 0.7072 - val_loss: 3.1972 - val_accuracy: 0.6837\n",
    "Epoch 100/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.4034e-07 - accuracy: 0.7077 - val_loss: 3.2089 - val_accuracy: 0.6840\n",
    "Epoch 101/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.8114e-07 - accuracy: 0.7083 - val_loss: 3.2216 - val_accuracy: 0.6849\n",
    "Epoch 102/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 5.2810e-07 - accuracy: 0.7092 - val_loss: 3.2348 - val_accuracy: 0.6860\n",
    "Epoch 103/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.7881e-07 - accuracy: 0.7101 - val_loss: 3.2486 - val_accuracy: 0.6874\n",
    "Epoch 104/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.3473e-07 - accuracy: 0.7115 - val_loss: 3.2612 - val_accuracy: 0.6876\n",
    "Epoch 105/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.9043e-07 - accuracy: 0.7129 - val_loss: 3.2775 - val_accuracy: 0.6883\n",
    "Epoch 106/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.5096e-07 - accuracy: 0.7136 - val_loss: 3.2960 - val_accuracy: 0.6892\n",
    "Epoch 107/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.1304e-07 - accuracy: 0.7154 - val_loss: 3.3091 - val_accuracy: 0.6899\n",
    "Epoch 108/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.8164e-07 - accuracy: 0.7168 - val_loss: 3.3277 - val_accuracy: 0.6917\n",
    "Epoch 109/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.4663e-07 - accuracy: 0.7180 - val_loss: 3.3451 - val_accuracy: 0.6930\n",
    "Epoch 110/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.1381e-07 - accuracy: 0.7210 - val_loss: 3.3692 - val_accuracy: 0.6949\n",
    "Epoch 111/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.0528e-07 - accuracy: 0.7225 - val_loss: 3.3853 - val_accuracy: 0.6978\n",
    "Epoch 112/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.8632e-07 - accuracy: 0.7253 - val_loss: 3.4080 - val_accuracy: 0.6990\n",
    "Epoch 113/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.0249e-06 - accuracy: 0.7338 - val_loss: 3.4579 - val_accuracy: 0.7094\n",
    "Epoch 114/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.2313e-04 - accuracy: 0.7333 - val_loss: 3.5653 - val_accuracy: 0.7123\n",
    "Epoch 115/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.3918e-04 - accuracy: 0.7269 - val_loss: 3.3964 - val_accuracy: 0.7055\n",
    "Epoch 116/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0026 - accuracy: 0.7191 - val_loss: 3.1772 - val_accuracy: 0.6806\n",
    "Epoch 117/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 0.0011 - accuracy: 0.7093 - val_loss: 3.2756 - val_accuracy: 0.6863\n",
    "Epoch 118/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.1081e-07 - accuracy: 0.7100 - val_loss: 3.2729 - val_accuracy: 0.6860\n",
    "Epoch 119/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.3656e-07 - accuracy: 0.7099 - val_loss: 3.2735 - val_accuracy: 0.6858\n",
    "Epoch 120/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.8155e-07 - accuracy: 0.7097 - val_loss: 3.2759 - val_accuracy: 0.6858\n",
    "Epoch 121/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.3504e-07 - accuracy: 0.7098 - val_loss: 3.2788 - val_accuracy: 0.6856\n",
    "Epoch 122/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.9244e-07 - accuracy: 0.7100 - val_loss: 3.2830 - val_accuracy: 0.6856\n",
    "Epoch 123/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.5581e-07 - accuracy: 0.7102 - val_loss: 3.2871 - val_accuracy: 0.6856\n",
    "Epoch 124/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.2177e-07 - accuracy: 0.7104 - val_loss: 3.2929 - val_accuracy: 0.6856\n",
    "Epoch 125/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.9022e-07 - accuracy: 0.7108 - val_loss: 3.2981 - val_accuracy: 0.6860\n",
    "Epoch 126/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.6197e-07 - accuracy: 0.7113 - val_loss: 3.3057 - val_accuracy: 0.6860\n",
    "Epoch 127/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.3825e-07 - accuracy: 0.7117 - val_loss: 3.3139 - val_accuracy: 0.6862\n",
    "Epoch 128/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.1435e-07 - accuracy: 0.7122 - val_loss: 3.3202 - val_accuracy: 0.6867\n",
    "Epoch 129/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.9494e-07 - accuracy: 0.7128 - val_loss: 3.3296 - val_accuracy: 0.6878\n",
    "Epoch 130/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.7767e-07 - accuracy: 0.7136 - val_loss: 3.3374 - val_accuracy: 0.6874\n",
    "Epoch 131/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.6490e-07 - accuracy: 0.7148 - val_loss: 3.3452 - val_accuracy: 0.6885\n",
    "Epoch 132/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4464e-07 - accuracy: 0.7153 - val_loss: 3.3543 - val_accuracy: 0.6892\n",
    "Epoch 133/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3184e-07 - accuracy: 0.7165 - val_loss: 3.3641 - val_accuracy: 0.6906\n",
    "Epoch 134/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.1750e-07 - accuracy: 0.7174 - val_loss: 3.3769 - val_accuracy: 0.6917\n",
    "Epoch 135/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0396e-07 - accuracy: 0.7183 - val_loss: 3.3866 - val_accuracy: 0.6919\n",
    "Epoch 136/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.0787e-08 - accuracy: 0.7202 - val_loss: 3.3981 - val_accuracy: 0.6940\n",
    "Epoch 137/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.0094e-08 - accuracy: 0.7213 - val_loss: 3.4094 - val_accuracy: 0.6949\n",
    "Epoch 138/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.9433e-08 - accuracy: 0.7235 - val_loss: 3.4242 - val_accuracy: 0.6969\n",
    "Epoch 139/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.9506e-08 - accuracy: 0.7252 - val_loss: 3.4375 - val_accuracy: 0.6981\n",
    "Epoch 140/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.1342e-08 - accuracy: 0.7273 - val_loss: 3.4475 - val_accuracy: 0.6994\n",
    "Epoch 141/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.2477e-08 - accuracy: 0.7294 - val_loss: 3.4640 - val_accuracy: 0.7010\n",
    "Epoch 142/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.6143e-08 - accuracy: 0.7311 - val_loss: 3.4777 - val_accuracy: 0.7039\n",
    "Epoch 143/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.9910e-08 - accuracy: 0.7338 - val_loss: 3.4938 - val_accuracy: 0.7042\n",
    "Epoch 144/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.4929e-08 - accuracy: 0.7348 - val_loss: 3.5050 - val_accuracy: 0.7062\n",
    "Epoch 145/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.0728e-08 - accuracy: 0.7371 - val_loss: 3.5214 - val_accuracy: 0.7080\n",
    "Epoch 146/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.7032e-08 - accuracy: 0.7397 - val_loss: 3.5310 - val_accuracy: 0.7085\n",
    "Epoch 147/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.4541e-08 - accuracy: 0.7406 - val_loss: 3.5369 - val_accuracy: 0.7087\n",
    "Epoch 148/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2354e-08 - accuracy: 0.7424 - val_loss: 3.5390 - val_accuracy: 0.7112\n",
    "Epoch 149/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0341e-08 - accuracy: 0.7440 - val_loss: 3.5404 - val_accuracy: 0.7116\n",
    "Epoch 150/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.9472e-09 - accuracy: 0.7448 - val_loss: 3.5398 - val_accuracy: 0.7130\n",
    "Epoch 151/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.6546e-09 - accuracy: 0.7462 - val_loss: 3.5351 - val_accuracy: 0.7133\n",
    "Epoch 152/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.7458e-09 - accuracy: 0.7472 - val_loss: 3.5270 - val_accuracy: 0.7141\n",
    "Epoch 153/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.9850e-09 - accuracy: 0.7482 - val_loss: 3.5134 - val_accuracy: 0.7149\n",
    "Epoch 154/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.5609e-09 - accuracy: 0.7479 - val_loss: 3.5023 - val_accuracy: 0.7160\n",
    "Epoch 155/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.8607e-09 - accuracy: 0.7490 - val_loss: 3.4928 - val_accuracy: 0.7166\n",
    "Epoch 156/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.6588e-09 - accuracy: 0.7492 - val_loss: 3.4851 - val_accuracy: 0.7176\n",
    "Epoch 157/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.0865e-09 - accuracy: 0.7493 - val_loss: 3.4662 - val_accuracy: 0.7173\n",
    "Epoch 158/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.0932e-09 - accuracy: 0.7501 - val_loss: 3.4540 - val_accuracy: 0.7185\n",
    "Epoch 159/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.9047e-09 - accuracy: 0.7507 - val_loss: 3.4220 - val_accuracy: 0.7166\n",
    "Epoch 160/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.5075e-09 - accuracy: 0.7503 - val_loss: 3.4023 - val_accuracy: 0.7175\n",
    "Epoch 161/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.2382e-09 - accuracy: 0.7497 - val_loss: 3.3552 - val_accuracy: 0.7164\n",
    "Epoch 162/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.9824e-09 - accuracy: 0.7508 - val_loss: 3.3444 - val_accuracy: 0.7171\n",
    "Epoch 163/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.7737e-09 - accuracy: 0.7507 - val_loss: 3.3085 - val_accuracy: 0.7167\n",
    "Epoch 164/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.8208e-09 - accuracy: 0.7500 - val_loss: 3.2948 - val_accuracy: 0.7175\n",
    "Epoch 165/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.6727e-09 - accuracy: 0.7515 - val_loss: 3.2698 - val_accuracy: 0.7166\n",
    "Epoch 166/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.4102e-09 - accuracy: 0.7526 - val_loss: 3.2838 - val_accuracy: 0.7198\n",
    "Epoch 167/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.2149e-09 - accuracy: 0.7544 - val_loss: 3.2732 - val_accuracy: 0.7223\n",
    "Epoch 168/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 2.1476e-09 - accuracy: 0.7575 - val_loss: 3.2563 - val_accuracy: 0.7242\n",
    "Epoch 169/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.8716e-09 - accuracy: 0.7597 - val_loss: 3.2661 - val_accuracy: 0.7269\n",
    "Epoch 170/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.6831e-09 - accuracy: 0.7618 - val_loss: 3.2464 - val_accuracy: 0.7242\n",
    "Epoch 171/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.6965e-09 - accuracy: 0.7648 - val_loss: 3.2787 - val_accuracy: 0.7325\n",
    "Epoch 172/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3465e-09 - accuracy: 0.7703 - val_loss: 3.2839 - val_accuracy: 0.7328\n",
    "Epoch 173/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3263e-09 - accuracy: 0.7712 - val_loss: 3.2700 - val_accuracy: 0.7355\n",
    "Epoch 174/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.3869e-09 - accuracy: 0.7743 - val_loss: 3.2856 - val_accuracy: 0.7387\n",
    "Epoch 175/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2186e-09 - accuracy: 0.7765 - val_loss: 3.2790 - val_accuracy: 0.7393\n",
    "Epoch 176/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.2387e-09 - accuracy: 0.7778 - val_loss: 3.2878 - val_accuracy: 0.7414\n",
    "Epoch 177/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0974e-09 - accuracy: 0.7812 - val_loss: 3.3076 - val_accuracy: 0.7452\n",
    "Epoch 178/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.7520e-10 - accuracy: 0.7846 - val_loss: 3.3238 - val_accuracy: 0.7443\n",
    "Epoch 179/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 9.7619e-10 - accuracy: 0.7844 - val_loss: 3.3235 - val_accuracy: 0.7459\n",
    "Epoch 180/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 1.0166e-09 - accuracy: 0.7869 - val_loss: 3.3406 - val_accuracy: 0.7500\n",
    "Epoch 181/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.4154e-10 - accuracy: 0.7915 - val_loss: 3.3636 - val_accuracy: 0.7518\n",
    "Epoch 182/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.0115e-10 - accuracy: 0.7948 - val_loss: 3.3937 - val_accuracy: 0.7545\n",
    "Epoch 183/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 8.2134e-10 - accuracy: 0.7971 - val_loss: 3.4130 - val_accuracy: 0.7577\n",
    "Epoch 184/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.2709e-10 - accuracy: 0.7997 - val_loss: 3.4264 - val_accuracy: 0.7591\n",
    "Epoch 185/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.5977e-10 - accuracy: 0.8027 - val_loss: 3.4582 - val_accuracy: 0.7639\n",
    "Epoch 186/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.6748e-10 - accuracy: 0.8040 - val_loss: 3.5013 - val_accuracy: 0.7648\n",
    "Epoch 187/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.2036e-10 - accuracy: 0.8064 - val_loss: 3.5158 - val_accuracy: 0.7713\n",
    "Epoch 188/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.4630e-10 - accuracy: 0.8088 - val_loss: 3.5548 - val_accuracy: 0.7659\n",
    "Epoch 189/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 7.2036e-10 - accuracy: 0.8102 - val_loss: 3.5711 - val_accuracy: 0.7695\n",
    "Epoch 190/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.3185e-10 - accuracy: 0.8158 - val_loss: 3.6277 - val_accuracy: 0.7740\n",
    "Epoch 191/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.3185e-10 - accuracy: 0.8175 - val_loss: 3.6788 - val_accuracy: 0.7761\n",
    "Epoch 192/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.7898e-10 - accuracy: 0.8196 - val_loss: 3.7305 - val_accuracy: 0.7817\n",
    "Epoch 193/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.5878e-10 - accuracy: 0.8231 - val_loss: 3.7664 - val_accuracy: 0.7800\n",
    "Epoch 194/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 6.3957e-10 - accuracy: 0.8246 - val_loss: 3.8238 - val_accuracy: 0.7856\n",
    "Epoch 195/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 5.3185e-10 - accuracy: 0.8274 - val_loss: 3.8742 - val_accuracy: 0.7917\n",
    "Epoch 196/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.3662e-10 - accuracy: 0.8320 - val_loss: 3.9159 - val_accuracy: 0.7904\n",
    "Epoch 197/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 4.3087e-10 - accuracy: 0.8328 - val_loss: 3.9620 - val_accuracy: 0.7897\n",
    "Epoch 198/200\n",
    "17707/17707 [==============================] - 20s 1ms/sample - loss: 3.8719e-04 - accuracy: 0.8373 - val_loss: 4.3451 - val_accuracy: 0.8171\n",
    "Epoch 199/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 8.1781e-04 - accuracy: 0.8515 - val_loss: 4.3174 - val_accuracy: 0.8205\n",
    "Epoch 200/200\n",
    "17707/17707 [==============================] - 19s 1ms/sample - loss: 0.0030 - accuracy: 0.8472 - val_loss: 4.2113 - val_accuracy: 0.8294\n",
    "WARNING:tensorflow:From /home/khanhi83/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "If using Keras pass *_constraint arguments to layers.\n",
    "INFO:tensorflow:Assets written to: model/assets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/home/khanhi83/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,5,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,87,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,117,118,119,121,122,123,124,125,126,127,128,130,131,132,145,146,148,215,224) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "  interactivity=interactivity, compiler=compiler, result=result)\n",
    "Dropped 3198 records because Text was null or NaN\n",
    "Dropped 4438 records because False Warning was null or NaN\n",
    "Converting text to feature matrix\n",
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "/home/khanhi83/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
    "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
    "Training accuracy with Random Forest: 0.9952561134014797\n",
    "Validation accuracy with Random Forest: 0.9281115879828327"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/home/khanhi83/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,5,9,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,87,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,117,118,119,121,122,123,124,125,126,127,128,130,131,132,145,146,148,215,224) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "  interactivity=interactivity, compiler=compiler, result=result)\n",
    "Dropped 3198 records because Text was null or NaN\n",
    "Dropped 4438 records because False Warning was null or NaN\n",
    "Converting text to feature matrix\n",
    "Training on 17707 sample, validating on 932 samples\n",
    "Number of features: 2285\n",
    "Training accuracy with kNN: 0.9435816343818829\n",
    "Validation accuracy with kNN: 0.9334763948497854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
